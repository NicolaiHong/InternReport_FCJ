[
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen đội ngũ và nắm vững các khái niệm cơ bản về AWS\nTuần 2: Định hướng dự án game gõ chữ, xây dựng microservice trên AWS và nền tảng vận hành\nTuần 3: Thực hành AWS, tài liệu UI/UX và tích hợp NoSQL cho dự án 1\nTuần 4: RDS, Auto Scaling, CloudWatch, Route 53, CLI, CI/CD, Docker, Serverless, và Security Hub\nTuần 5: Từ mạng đến triển khai: VPC Peering, Transit Gateway, WordPress, tối ưu chi phí Lambda, CI/CD, Storage Gateway, FSx \u0026amp; WAF\nTuần 6: Quản lý truy cập IAM, hệ thống giám sát (Grafana \u0026amp; CloudWatch), Systems Manager, tối ưu kích thước EC2, mã hóa S3, Cost Explorer, data lake và tự động hóa với CloudFormation\nTuần 7: Đào sâu DynamoDB, liên kết IAM federation \u0026amp; tối ưu chi phí, Lightsail \u0026amp; containers, Step Functions, Cloud9, Elastic Beanstalk, pipeline CI/CD và nền tảng bảo mật AWS\nTuần 8: IaC với CloudFormation, độ bền \u0026amp; auto scaling, tách thành microservices, SPA serverless với Cognito \u0026amp; X-Ray, dịch vụ AI (Polly, Rekognition, Lex), S3 \u0026amp; CloudFront, và dashboard CloudWatch\nTuần 9: Chatbot Lex \u0026amp; mô hình pub/sub SNS, lab DynamoDB \u0026amp; ElastiCache, EKS CI/CD \u0026amp; Blueprints, microservices serverless \u0026amp; Fargate, đánh giá hiệu năng lưu trữ, best practices bảo mật S3, và data lake với Glue, Athena \u0026amp; QuickSight\nTuần 10: Triển khai ROSA, nền tảng phân tích với Kinesis, Glue, EMR, Athena, QuickSight \u0026amp; Redshift, dashboard nghiệp vụ, VPC Flow Logs, ủy quyền billing, CDK, event-driven (SNS/SQS) và full serverless stack với Cognito, CloudFront, SQS/SNS cùng CI/CD\nTuần 11: Sự kiện cộng đồng AWS, dịch vụ text serverless với DynamoDB, caching \u0026amp; validation, tích hợp Amazon Bedrock Agent, giám sát bằng CloudWatch \u0026amp; X-Ray, và API GraphQL với AppSync \u0026amp; DynamoDB\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.2-prerequiste/",
	"title": "Yêu cầu trước khi bắt đầu",
	"tags": [],
	"description": "",
	"content": "Kiến thức AWS cần thiết AWS Console Navigation: Khả năng điều hướng AWS Management Console và tìm kiếm các dịch vụ Basic AWS Concepts: Hiểu biết về AWS regions, availability zones và các tương tác dịch vụ cơ bản Không cần kinh nghiệm trước với S3, CloudFront hoặc WAF - chúng tôi sẽ hướng dẫn từng bước Kỹ năng kỹ thuật cần thiết Basic Web Development: Hiểu biết về HTML, CSS và JavaScript File System Operations: Khả năng tạo, chỉnh sửa và tổ chức các tệp và thư mục Command Line Basics: Thoải mái với việc chạy các lệnh terminal/command prompt cơ bản Text Editing: Quen thuộc với bất kỳ code editor hoặc IDE nào Thiết lập tài khoản AWS cần thiết Trước khi bắt đầu workshop này, hãy đảm bảo bạn có:\nAWS Account\nTài khoản AWS đang hoạt động với quyền truy cập quản trị Thẻ tín dụng đã đăng ký (bắt buộc ngay cả với Free Tier) MFA (Multi-Factor Authentication) được bật trên tài khoản root (khuyến nghị mạnh mẽ) IAM User (Khuyến nghị)\nIAM user với các quyền phù hợp thay vì sử dụng tài khoản root Các quyền cần thiết: AmazonS3FullAccess CloudFrontFullAccess WAFv2FullAccess AWSCertificateManagerFullAccess (nếu sử dụng custom domain) Access key và secret key đã được tạo (để truy cập CLI) Billing Alerts\nThiết lập AWS Budgets hoặc billing alerts để theo dõi chi phí Khuyến nghị: Đặt cảnh báo ở ngưỡng $10 Công cụ và phần mềm cần thiết Cài đặt các công cụ sau trên máy tính của bạn:\nText Editor hoặc IDE\nVS Code (khuyến nghị): https://code.visualstudio.com/ Hoặc bất kỳ editor nào bạn chọn (Sublime Text, Atom, v.v.) Web Browser\nTrình duyệt hiện đại (Chrome, Firefox, Safari hoặc Edge) Khuyến nghị nhiều tab để điều hướng console Git (Tùy chọn nhưng khuyến nghị)\nTải về: https://git-scm.com/ Sử dụng cho version control và lấy mã nguồn mẫu Ứng dụng mẫu Chúng tôi sẽ cung cấp một trang web tĩnh đơn giản cho workshop này.\nTùy chọn: Thiết lập Custom Domain Nếu bạn muốn sử dụng custom domain (ví dụ: www.yoursite.com):\nDomain Name: Tên miền đã đăng ký (có thể sử dụng Route 53 hoặc nhà đăng ký bên ngoài) DNS Access: Khả năng sửa đổi các bản ghi DNS cho tên miền của bạn Lưu ý: Đây là tùy chọn; bạn có thể hoàn thành workshop bằng cách sử dụng tên miền mặc định của CloudFront Dự kiến chi phí cho Part 1: Frontend Deployment Các dịch vụ đủ điều kiện Free Tier:\nS3: 5GB lưu trữ, 20,000 GET requests, 2,000 PUT requests (12 tháng đầu) CloudFront: 1TB data transfer out, 10,000,000 HTTP/HTTPS requests (12 tháng đầu) AWS WAF: Không có Free Tier, nhưng chi phí tối thiểu cho các quy tắc cơ bản Chi phí ước tính (nếu vượt quá Free Tier):\nS3 storage: $0.023 mỗi GB mỗi tháng CloudFront data transfer: $0.085 mỗi GB (thay đổi theo region) WAF: $5.00 mỗi tháng cho mỗi web ACL + $1.00 cho mỗi rule mỗi tháng Tổng chi phí ước tính cho workshop này: $0-$2 (trong Free Tier) hoặc $5-$10 (với WAF) Mẹo tiết kiệm chi phí:\nXóa tài nguyên ngay sau workshop nếu không tiếp tục Sử dụng các tệp mẫu nhỏ để giảm thiểu chi phí lưu trữ và truyền tải Bắt đầu với các quy tắc WAF cơ bản và mở rộng sau Sẵn sàng bắt đầu? Sau khi hoàn thành tất cả các yêu cầu và xác minh thiết lập của bạn, bạn đã sẵn sàng để bắt đầu xây dựng cơ sở hạ tầng frontend an toàn, được phân phối toàn cầu!\nHãy chuyển sang Part 1: S3 Static Website Hosting.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/4.1-event1/",
	"title": "Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch Mục tiêu Sự kiện Xây dựng một thế hệ AWS Builders chất lượng cao cho Việt Nam. Trang bị cho sinh viên những kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, và Data \u0026amp; Analytics. Kết nối sinh viên với cộng đồng AWS Study Group hơn 47.000 thành viên và các doanh nghiệp đối tác của AWS. Diễn giả Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Đỗ Huy Thắng – DevOps Lead, VNG Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific Những điểm nhấn chính Nhận diện những cạm bẫy phổ biến dẫn đến thất bại Chi tiêu cho những gì khiến bạn vui vẻ nhất thời mà bỏ qua những gì giúp bạn trở nên tốt hơn. Học một khóa học chỉ vì chức danh công việc thay vì xem đó là lợi thế cạnh tranh -\u0026gt; Sẽ không ai xem bạn là một nhân sự có giá trị. Học tập là một hành trình cả đời và không ai có thể đi đường tắt trên thang bậc tri thức. Hành trình tìm kiếm cơ hội việc làm Không ai có con đường dễ dàng khi tìm kiếm việc làm. Đó là một chặng đường dài và đầy thử thách, đòi hỏi sự chăm chỉ và khả năng nắm bắt cơ hội. What awaits me at AWS First Cloud Journey Một cách để kết nối với những người xung quanh và tìm những người bạn đồng hành cùng tôi trong AWS First Cloud Journey và thậm chí là trong cuộc sống. Rất nhiều thử thách mà tôi cần phải vượt qua để trở thành một phiên bản tốt hơn của chính mình. Những cơ hội để có kinh nghiệm thực hành nhằm nâng cao hơn nữa khả năng của mình. Bài học đúc kết Ưu tiên phát triển dài hạn hơn niềm vui ngắn hạn Thành công đòi hỏi việc đầu tư vào các kỹ năng xây dựng giá trị tương lai của bạn, không chỉ là chi tiêu cho những thú vui tạm thời. Hãy tiếp cận việc học như một cách để đạt được lợi thế cạnh tranh thực sự, thay vì chỉ để thu thập một chức danh công việc, để trở thành một chuyên gia thực sự có giá trị.\nEmbrace the Challenge as a Lifelong Journey Hãy hiểu rằng việc có được cơ hội nghề nghiệp là một quá trình khó khăn đòi hỏi sự chăm chỉ và bền bỉ. Không có con đường tắt trên thang bậc tri thức; hãy xem mọi thử thách là một bước cần thiết để trở thành một phiên bản tốt hơn của chính mình.\nTrải nghiệm tại Sự kiện Việc tham dự buổi hội thảo “Kick-off AWS First Cloud Journey” vô cùng giá trị, mang lại cho tôi một nền tảng vững chắc về các khái niệm thiết yếu, những kỹ năng thực tế để bắt đầu xây dựng, và nguồn cảm hứng để tiếp tục hành trình học tập suốt đời trên nền tảng đám mây. Các trải nghiệm chính bao gồm:\nHọc hỏi từ các diễn giả giàu chuyên môn Sự kiện đã mang đến một trải nghiệm học hỏi đa chiều, kết hợp tầm nhìn chiến lược của ngành với những lời khuyên nghề nghiệp thực tế. Chúng tôi đã được nghe tổng quan chiến lược về tương lai của đám mây từ anh Nguyễn Gia Hưng, Trưởng bộ phận Kiến trúc sư giải pháp tại AWS Việt Nam, và có được những hiểu biết sâu sắc về vai trò quan trọng của DevOps từ anh Đỗ Huy Thắng, Trưởng nhóm DevOps tại VNG. Điều này được bổ sung hoàn hảo bởi những câu chuyện gần gũi và truyền cảm hứng từ các cựu học viên của chương trình, những người đã chia sẻ hành trình cá nhân từ khi còn là sinh viên đến khi trở thành các chuyên gia trong các lĩnh vực như Kỹ sư GenAI và Kỹ sư Cloud. Việc được nghe trực tiếp về \u0026ldquo;một ngày làm việc\u0026rdquo; và quá trình chuyển đổi từ chương trình sang một công việc công nghệ toàn thời gian đã cung cấp một bức tranh rõ ràng và hữu hình về con đường phía trước.\nKết nối và thảo luận Từ lúc check-in cho đến giờ nghỉ giải lao, không khí luôn tràn đầy năng lượng. Đây là những cơ hội vô giá để kết nối với các bạn sinh viên khác, những người sẽ là đồng nghiệp và cộng tác viên của chúng tôi trong suốt chương trình Đào tạo tại Doanh nghiệp (OJT) này. Ngoài việc kết nối với bạn bè, phiên Hỏi \u0026amp; Đáp cuối chương trình là một điểm nhấn, cho phép chúng tôi tương tác trực tiếp với các diễn giả và cố vấn. Diễn đàn mở này đã tạo cơ hội để đặt những câu hỏi cụ thể về con đường sự nghiệp, thách thức kỹ thuật và phát triển cá nhân, biến dòng thông tin một chiều thành một cuộc thảo luận năng động và mang tính hợp tác.\nNhững bài học kinh nghiệm Ba bài học cốt lõi đã nổi bật sau sự kiện. Đầu tiên, điện toán đám mây là bệ phóng nền tảng cho các ngành nghề hiện đại, không chỉ là một điểm đến duy nhất; đó là cánh cổng dẫn đến các chuyên ngành về AI, DevOps, Bảo mật và Dữ liệu. Thứ hai, hành trình này là một cuộc đua marathon, không phải chạy nước rút. Những câu chuyện đa dạng từ các cựu học viên nhấn mạnh rằng chương trình này là một bước khởi đầu quan trọng, nhưng việc học hỏi liên tục và sự kiên cường mới là yếu tố định hình một sự nghiệp thành công. Cuối cùng, cộng đồng là một chất xúc tác mạnh mẽ. Sự kiện đã khẳng định rằng giờ đây chúng tôi là một phần của một hệ sinh thái lớn hơn—cộng đồng AWS Builders—nơi sự hợp tác và chia sẻ kiến thức là điều cần thiết cho sự phát triển.\nMột vài hình ảnh tại sự kiện Nhìn chung, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi định hình lại tư duy về cách học và khuyến khích tôi tiếp tục nỗ lực hơn nữa.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Hồng Lê Đăng Khoa\nSố điện thoại: 0773018623\nEmail: hongkhoa348@gmail.com\nTrường: Đại học FPT Campus Thành phố Hồ Chí Minh\nNgành: Kỹ thuật phần mền\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ 09/2025 đến 02/2026\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.1-week1/",
	"title": "Nhật ký công việc Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 1: Giới thiệu bản thân và kết nối với nhóm First Cloud Journey. Học cách viết worklog và cách tổ chức/workshop. Hiểu các dịch vụ cơ bản của AWS và biết cách sử dụng AWS Management Console và AWS CLI. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Làm quen và giới thiệu với các thành viên FCJ - Đọc và ghi chú các quy định và nội quy thực tập 09/08/2025 09/08/2025 Policies: https://policies.fcjuni.com/ 3 - Tìm hiểu về AWS và các nhóm dịch vụ chính phục vụ dự án sau này + Compute + Storage + Networking + Database + Khác - Xem hướng dẫn/video về cách tổ chức workshop và viết tài liệu 09/09/2025 09/09/2025 About AWS: https://cloudjourney.awsstudygroup.com/ About workshop: https://van-hoang-kha.github.io/vi/ 4 - Áp dụng hướng dẫn viết workshop để soạn worklog này - Tạo tài khoản AWS Free Tier - Tìm hiểu AWS Management Console và cài đặt/cấu hình AWS CLI - Thực hành: + Tạo tài khoản AWS + Cài \u0026amp; cấu hình AWS CLI + Sử dụng cơ bản AWS CLI 09/10/2025 09/10/2025 My workshop git: https://github.com/isntbim/internship_report AWS Console: https://aws.amazon.com/ 5 - Học các khái niệm cơ bản về EC2: + Các loại instance + AMI + EBS + Lưu trữ - Thử khởi chạy instance EC2 - Các phương thức kết nối SSH tới EC2 - Tìm hiểu về Elastic IP 09/11/2025 09/11/2025 EC2 console: https://ap-southeast-1.console.aws.amazon.com/ec2/ Amazon EC2 Basics: https://www.coursera.org/learn/aws-amazon-ec2-basics/ 6 - Thực hành thêm: + Khởi chạy một EC2 instance + Kết nối qua SSH + Gắn thêm ổ EBS 09/12/2025 09/12/2025 EC2 console: https://ap-southeast-1.console.aws.amazon.com/ec2/ Thành tựu Tuần 1 (đang tiếp tục): Nắm được khái niệm về AWS và làm quen với các nhóm dịch vụ chính:\nCompute Storage Networking Database Các dịch vụ khác Đã tạo và cấu hình thành công tài khoản AWS Free Tier.\nLàm quen với định dạng workshop và cách viết worklog.\nThành thạo thao tác cơ bản trên AWS Management Console: tìm, truy cập và sử dụng dịch vụ qua giao diện web.\nCài đặt và cấu hình AWS CLI, bao gồm:\nAccess Key Secret Key Vùng mặc định (Default Region) Các thiết lập liên quan Hiểu các khái niệm cơ bản về EC2:\nCác loại instance — cân bằng giữa chi phí và hiệu năng. AMI — ảnh máy/ảnh hệ điều hành dùng để khởi tạo instance. EBS — ổ lưu trữ block bền cho instance. Các lựa chọn lưu trữ — chọn loại lưu trữ phù hợp theo nhu cầu. Elastic IP — địa chỉ IP tĩnh gán cho instance trong môi trường đám mây. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Nền tảng Thử thách Gõ phím Thời gian Thực TypeRush Kiến trúc do AWS vận hành cho một ứng dụng gõ phím nhiều người chơi 1. Tóm tắt điều hành TypeRush là một ứng dụng web tương tác tái hiện trải nghiệm cốt lõi của Monkeytype đồng thời giới thiệu chức năng nhiều người chơi cho các phiên gõ phím cạnh tranh trực tiếp. Được thiết kế như một bản trình diễn các công nghệ web thời gian thực và kiến trúc đám mây có khả năng mở rộng, nền tảng kết hợp trải nghiệm frontend hiện đại với backend serverless chạy trên AWS.\nNgười dùng có thể tạo hoặc tham gia phòng gõ phím, thi đấu theo thời gian thực và xem các chỉ số hiệu suất như Words Per Minute (WPM), độ chính xác và xếp hạng. Ứng dụng tận dụng React cho frontend, AWS Lambda và API Gateway (WebSocket) cho đồng bộ thời gian thực, Amazon RDS cho dữ liệu người chơi và Amazon ElastiCache cho dữ liệu phiên. Ứng dụng cũng sử dụng Amazon Bedrock để tạo thử thách hằng ngày. Amazon Cognito bảo đảm truy cập và xác thực người dùng. Giải pháp minh họa cách các dịch vụ cloud-native có thể cung cấp các ứng dụng thời gian thực nhanh, có khả năng mở rộng và chi phí hiệu quả mà không cần quản lý máy chủ truyền thống.\n2. Tuyên bố vấn đề Vấn đề là gì? Các nền tảng gõ phím hiện có thường bị giới hạn ở chế độ một người chơi, thiếu tương tác nhiều người chơi theo thời gian thực hoặc ví dụ triển khai mở. Hầu hết các giải pháp nhiều người chơi yêu cầu máy chủ chuyên dụng hoặc hạ tầng phức tạp, khiến chi phí cao và khó bảo trì. Đối với nhà phát triển và người đam mê, không có ví dụ serverless dễ tiếp cận nào thể hiện đồng bộ thời gian thực, cập nhật theo sự kiện và quản lý người dùng an toàn trong một hệ thống tích hợp.\nGiải pháp Dự án này cung cấp một nền tảng gõ phím thời gian thực theo kiểu serverless cho phép nhiều người dùng kết nối, gõ đồng thời và thấy phản hồi tức thì về tiến độ của họ. Nó được thiết kế nhẹ, chi phí hiệu quả và có khả năng mở rộng.\nLợi ích và Hoàn vốn (ROI) Dự án vừa là nền tảng học tập cho nhà phát triển vừa là ứng dụng hướng tới người dùng. Nó trình diễn các thực tiễn tốt nhất trong kiến trúc hướng sự kiện, triển khai WebSocket và khả năng mở rộng dựa trên đám mây với chi phí vận hành tối thiểu. Đối với người dùng, nó mang lại trải nghiệm gõ phím mang tính xã hội, lôi cuốn. Đối với nhà phát triển, nó cung cấp tài liệu tham khảo giáo dục để xây dựng các hệ thống serverless thời gian thực.\nNền tảng không cần bảo trì máy chủ liên tục, bảo đảm:\nTính bền vững dài hạn Khả năng mở rộng nhanh Chi phí vận hành thấp 3. Kiến trúc giải pháp Nền tảng sử dụng kiến trúc AWS serverless để quản lý một ứng dụng thử thách gõ phím thời gian thực. Dữ liệu được xử lý và lưu trữ bằng nhiều dịch vụ AWS, và frontend là một giao diện hiện đại, đáp ứng. Kiến trúc chi tiết bên dưới: Dịch vụ AWS sử dụng Amazon S3: Lưu trữ frontend tĩnh. CloudFront: Cung cấp CDN cho frontend và API. AWS WAF: Hoạt động như tường lửa cho CloudFront. Route 53: Quản lý tên miền và định tuyến DNS. Amazon Cognito: Xử lý đăng nhập và đăng ký người dùng. API Gateway: Cổng vào cho các microservice và kết nối tới ECS riêng tư qua VPC Link. AWS Lambda: Vận hành microservice record và text, và WebSocket API cho microservice game. Amazon RDS: Lưu trữ bản ghi và bảng xếp hạng. DynamoDB: Lưu trữ dữ liệu văn bản. AWS Bedrock (Titan Text G1 Express): Hoạt động như mô hình LLM để tạo văn bản. Amazon SNS: Quản lý thông báo và cảnh báo. AWS CloudWatch: Xử lý logging và monitoring. AWS Secrets Manager: Lưu trữ bí mật cho cơ sở dữ liệu và API. Amazon ECS (Fargate): Lưu trữ backend cốt lõi của game. Elastic Load Balancer: Cân bằng tải cho dịch vụ game. ElastiCache (Redis): Cache dữ liệu game thời gian thực. CodePipeline: Điều phối build và triển khai. CodeBuild: Build image Docker và dịch vụ Lambda. ECR (Elastic Container Registry): Lưu trữ image Docker. GitLab: Kích hoạt pipeline build. Thiết kế thành phần Frontend Layer: UI hiện đại, đáp ứng xây dựng bằng React, lưu trữ trên Amazon S3 và phục vụ qua Amazon CloudFront với AWS WAF và Amazon Route 53 để nâng cao hiệu năng, phân phối nội dung toàn cầu và bảo mật mạnh mẽ. API \u0026amp; Giao tiếp thời gian thực: AWS API Gateway đóng vai trò cổng hợp nhất cho cả REST và WebSocket API, triển khai rate limiting, xác thực và kiểm tra yêu cầu. WebSocket API cung cấp tương tác nhiều người chơi theo thời gian thực. Compute \u0026amp; Business Logic: AWS Lambda xử lý các tác vụ serverless như lưu trữ dữ liệu và tạo văn bản dùng AI. Amazon ECS với AWS Fargate lưu trữ các dịch vụ backend dạng container, bao gồm server trò chơi. VPC PrivateLink kết nối API Gateway với các container ECS Fargate, và Elastic Load Balancer phân phối lưu lượng. Data Layer: Amazon RDS lưu dữ liệu quan hệ như hồ sơ người dùng và bảng xếp hạng. Amazon DynamoDB quản lý dữ liệu phi quan hệ như văn bản tạo động. Amazon ElastiCache (Redis) cung cấp cache trong bộ nhớ cho dữ liệu truy cập thường xuyên. Xác thực \u0026amp; Quản lý người dùng: Amazon Cognito xử lý đăng ký, xác thực và ủy quyền an toàn, hỗ trợ đăng nhập xã hội và liên kết. Amazon Secrets Manager bảo mật lưu trữ các bí mật như khóa API. CI/CD \u0026amp; DevOps: AWS CodeBuild và AWS CodePipeline cho phép tích hợp liên tục và triển khai liên tục (CI/CD) trên tất cả các thành phần ứng dụng, tự động hóa build, test và triển khai. 4. Triển khai kỹ thuật Các giai đoạn triển khai Dự án này có hai phần — thiết lập hạ tầng đám mây và xây dựng ứng dụng — mỗi phần theo 4 giai đoạn:\nXây dựng lý thuyết và vẽ kiến trúc: Nghiên cứu và thiết kế kiến trúc AWS serverless. Tính giá và kiểm tra tính thực tiễn: Sử dụng AWS Pricing Calculator để ước tính chi phí và điều chỉnh khi cần. Sửa kiến trúc cho phù hợp chi phí/giải pháp: Tinh chỉnh thiết kế để giữ chi phí hiệu quả và dễ dùng. Phát triển, kiểm thử và triển khai: Lập trình ứng dụng và các dịch vụ AWS, sau đó kiểm thử và phát hành lên production. Yêu cầu kỹ thuật Frontend: Kiến thức thực hành về React. Backend: Kinh nghiệm với các dịch vụ AWS bao gồm Lambda, API Gateway, ECS, Fargate, RDS, DynamoDB và ElastiCache. CI/CD: Quen thuộc với CodePipeline, CodeBuild và GitLab. Hạ tầng như Mã (IaC): Sử dụng AWS CDK/SDK để mã hóa tương tác. 5. Dòng thời gian \u0026amp; Các mốc Dòng thời gian dự án\nTháng 1: Học tất cả về AWS và các dịch vụ AWS. Tháng 2: Bắt đầu lập kế hoạch cho dự án và các dịch vụ AWS sẽ triển khai. Tháng 3: Phát triển, triển khai và ra mắt. 6. Ước tính ngân sách \u0026mdash;\u0026gt; Tệp Ước tính Ngân sách \u0026lt;\u0026mdash;\nChi phí hạ tầng Dịch vụ AWS: Amazon Route 53: $0.90 AWS Web Application Firewall (WAF): $9.03 Amazon CloudFront: $0.40 ($0 với free tier) S3 Standard: $0.11 ($0 với free tier) Truyền dữ liệu: $0.00 ($0 với free tier) Amazon API Gateway: $15.92 ($0 với free tier) Amazon Cognito: $0.00 Network Load Balancer: $18.49 AWS Fargate: $8.88 AWS Lambda: $0.02 ($0 với free tier) Amazon ElastiCache: $16.06 Amazon RDS for PostgreSQL: $39.37 ($0 với free tier) AWS Bedrock (Workload 1): $2.63 DynamoDB: $0.03 ($0 với free tier) AWS Secrets Manager: $4.00 AWS CodePipeline: $1.00 ($0 với free tier) AWS CodeBuild: $5.00 ($0 với free tier) Với tài khoản free tier: khoảng $60/tháng Với tài khoản trả phí: khoảng $122/tháng Cả hai mức đều giả định dịch vụ chạy 24/7; thực tế có thể thấp hơn nhiều.\n7. Đánh giá rủi ro Ma trận rủi ro Tích hợp kỹ thuật: Ảnh hưởng trung bình, xác suất trung bình. Hiệu năng và Khả năng mở rộng: Ảnh hưởng cao, xác suất trung bình. Quản lý chi phí: Ảnh hưởng trung bình, xác suất trung bình. Bảo mật: Ảnh hưởng cao, xác suất thấp. Độ tin cậy dữ liệu: Ảnh hưởng trung bình, xác suất thấp. Rủi ro vận hành: Ảnh hưởng thấp, xác suất trung bình. Đường cong học tập: Ảnh hưởng trung bình, xác suất cao. Chiến lược giảm thiểu Tích hợp kỹ thuật: Rủi ro này được giảm thiểu bằng triển khai theo giai đoạn và tuân thủ các thực tiễn tốt nhất của AWS. Hiệu năng và Khả năng mở rộng: Tối ưu giao tiếp WebSocket, tận dụng cache Redis và giám sát với CloudWatch để duy trì độ phản hồi. Quản lý chi phí: Kiểm soát qua AWS Budgets, cảnh báo sử dụng và chính sách auto-scaling. Bảo mật: Giảm thiểu bằng AWS WAF, Cognito, Secrets Manager và chính sách IAM chặt chẽ. Độ tin cậy dữ liệu: Ranh giới sở hữu dữ liệu rõ ràng và ghi chép giao dịch bảo đảm tính nhất quán. Rủi ro vận hành: Rủi ro trong pipeline CI/CD được giảm bằng triển khai theo giai đoạn và cấu hình rollback. Đường cong học tập: Được giải quyết thông qua học tập có chủ đích và thực hành trong giai đoạn đầu của dự án. Kế hoạch dự phòng Nếu dịch vụ gặp sự cố: Một trang bảo trì sẽ hiển thị cho người dùng. Nếu chế độ nhiều người chơi quá chậm: Tạm thời vô hiệu hóa chế độ nhiều người chơi, nhưng chế độ một người chơi vẫn hoạt động. Nếu chi phí tăng đột biến: Thay đổi gây ra tăng chi phí sẽ được đảo ngược ngay lập tức. Nếu bản cập nhật mới làm hỏng trang: Hệ thống sẽ tự động quay lại phiên bản hoạt động trước đó. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Sau khi hoàn tất, dự án sẽ cung cấp một nền tảng gõ phím nhiều người chơi thời gian thực có khả năng mở rộng, an toàn và đầy đủ chức năng, được xây dựng hoàn toàn trên AWS.\nGiá trị dài hạn: Dự án sẽ minh họa các thực tiễn tốt nhất trong kiến trúc serverless, thiết kế hướng sự kiện và tự động hóa CI/CD. Với người dùng, nó mang lại trải nghiệm gõ phím nhiều người chơi mượt mà, hấp dẫn. Với chúng tôi, nó là mô hình tham chiếu thực hành đầu tiên để xây dựng các ứng dụng web serverless thời gian thực trên AWS với chi phí và bảo trì tối thiểu.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/4.2-event2/",
	"title": "Data Science trên AWS",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch Mục tiêu Sự kiện Cung cấp cái nhìn tổng quan toàn diện về việc xây dựng hệ thống Data Science hiện đại trên AWS. Giới thiệu end-to-end Data Science pipeline, từ data processing đến model deployment. Cung cấp hands-on với các dịch vụ chủ chốt như AWS Glue và Amazon SageMaker. Thảo luận các yếu tố thực tiễn như cost, performance, và lợi ích của cloud vs on-premise. Diễn giả Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder Bạch Doãn Vương – Cloud Develops Engineer, AWS Community Builder Nội dung Nổi bật End-to-End Data Science Pipeline trên AWS Workshop mô tả toàn bộ hành trình data science trên cloud, sử dụng các dịch vụ cốt lõi:\nAmazon S3: Lưu trữ dữ liệu scalable. AWS Glue: Serverless data integration, ETL (Extract, Transform, Load), và data cleaning. Amazon SageMaker: Để build, train và deploy machine learning models at scale. Trình diễn Thực hành Demo 1: Data Processing với AWS Glue: Trình diễn cách process và clean một real-world IMDb dataset, nhấn mạnh tầm quan trọng của data quality đối với model accuracy. Demo 2: Model Training với SageMaker: Minh họa quy trình train và deploy một Sentiment Analysis model, giúp các khái niệm ML deployment trở nên cụ thể. Tích hợp Custom Models: Trình bày cách leverage frameworks như TensorFlow và PyTorch trong SageMaker, sử dụng sample project từ một GitHub repository. Mở rộng Năng lực AI/ML với Managed Services Tổng quan về các pre-built AI services của AWS giúp tăng tốc phát triển:\nAmazon Transcribe: Speech-to-text conversion. Amazon Comprehend: Natural Language Processing cho sentiment analysis và topic extraction. Amazon Rekognition: Phân tích hình ảnh và video. Amazon Personalize: Xây dựng personalized recommendation systems. Những điểm nhấn chính Tư duy Data-First Business-first approach: Luôn bắt đầu từ business context của dữ liệu, được nhấn mạnh qua nhu cầu feature engineering. Data quality là tối quan trọng: Độ chính xác của bất kỳ ML model nào phụ thuộc trực tiếp vào chất lượng input data. Data như một tài sản: Data collection, governance và security là các trụ cột nền tảng của một data-driven organization. Kiến trúc Kỹ thuật Modular Pipeline: Kiến trúc tiêu chuẩn gồm pipeline từ S3 (storage) → AWS Glue (ETL) → Amazon SageMaker (ML), cho phép separation of concerns rõ ràng. Tính linh hoạt: AWS hỗ trợ cả low-code như SageMaker Canvas và code-intensive custom model training với TensorFlow/PyTorch. Lợi ích serverless: Dùng các services như AWS Glue giúp loại bỏ quản trị hạ tầng, cho phép teams tập trung vào data và models. Chiến lược Phased approach: Bắt đầu với data collection và cleaning trước khi chuyển sang model training phức tạp. Cloud vs On-premise: Cloud mang lại lợi thế về scalability, pay-for-what-you-use cost models, và khả năng truy cập tài nguyên compute mạnh mẽ mà không cần đầu tư ban đầu. Đo lường ROI: Tận dụng lợi ích cloud để giảm development time và infrastructure overhead, rút ngắn time-to-market cho AI-powered features. Ứng dụng vào Công việc Tự động hóa ETL: Dùng AWS Glue để tạo các job data cleaning và preparation tự động cho analytics và ML. Áp dụng SageMaker: Pilot Amazon SageMaker cho training và deploying ML models để streamline MLOps lifecycle. Triển khai Sentiment Analysis: Ứng dụng các khái niệm từ demo để phân tích phản hồi khách hàng từ reviews hoặc support tickets. Khai thác Pre-built AI: Tích hợp các services như Amazon Rekognition cho content moderation hoặc Amazon Transcribe cho call center analytics. Củng cố kiến thức: Xây dựng một project nhỏ dựa trên hướng dẫn của workshop để củng cố các khái niệm đã học. Trải nghiệm Sự kiện Tham dự workshop \u0026ldquo;Data Science on AWS\u0026rdquo; mang lại một hành trình hands-on giá trị về machine learning trên cloud. Một số trải nghiệm chính:\nHọc hỏi từ các diễn giả giàu kinh nghiệm Các diễn giả, đều là AWS Community Builders, chia sẻ practical insights và best practices từ kinh nghiệm thực tế. Trải nghiệm kỹ thuật hands-on Các live demo về processing data với AWS Glue và training model với SageMaker giúp chuyển hóa lý thuyết thành thực tiễn rất hiệu quả. Tận dụng công cụ hiện đại Khám phá hệ sinh thái AWS toàn diện cho data science, hiểu cách các dịch vụ kết hợp để tạo thành một cohesive pipeline. Tìm hiểu cả fully managed AI services và các tùy biến mạnh mẽ trong SageMaker. Bài học rút ra Chiến lược data preparation vững chắc là điều không thể thiếu để thành công trong machine learning. AWS giúp hạ thấp đáng kể rào cản xây dựng và triển khai các hệ thống data science tiên tiến. Nền tảng cloud hiện đại mang lại sự linh hoạt lựa chọn giữa low-code để tăng tốc và custom code cho các yêu cầu phức tạp, đặc thù. Một số hình ảnh sự kiện Tổng thể, workshop không chỉ mang lại kiến thức kỹ thuật mà còn trải nghiệm thực hành trong việc xây dựng end-to-end data science pipelines trên AWS, nhấn mạnh tầm quan trọng của data quality và sức mạnh của cloud-native ML services.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.2-week2/",
	"title": "Nhật ký công việc Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 2: Xác định và xác phạm vi cho dự án trò chơi gõ chữ đầu tiên (tính năng cốt lõi, ranh giới microservice, hướng phát triển matchmaking). Xây dựng nền tảng đội: repository chung, backlog khởi tạo, sơ đồ ER, lựa chọn tech stack, phân công ownership. Chuẩn hóa công thức tính WPM và accuracy. Prototype dịch vụ FastAPI: sinh văn bản, ghép câu, chat; kiểm chứng con đường tích hợp với Bedrock. Thiết lập AWS Budgets kèm cảnh báo. Nâng cao khả năng thực hành: Lambda (function URL), VPC (subnet, gateway, peering vs transit), VPC Flow Logs, khái niệm cân bằng tải. Provision Amazon RDS; thiết kế schema và seed dataset cho truy xuất văn bản. Refactor dịch vụ text sang truy xuất dựa trên DB; benchmark so sánh với phương pháp API trước đó. Giới thiệu các thực hành vận hành sớm: phân công vai trò, benchmark, giám sát để đảm bảo khả năng scale. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tổ chức buổi brainstorming nhóm để xác định và ưu tiên ý tưởng cho dự án đầu tiên + Chuyển ghi chú từ canvas dự án vào backlog khởi tạo trên bảng quản lý dự án + Nghiên cứu và ghi chép các thuật toán cụ thể để tính WPM và accuracy nhằm đảm bảo tính nhất quán + Tạo repository chung và thiết lập cấu trúc dự án cơ bản cho các ngôn ngữ và microservice đã chọn + Hoàn thiện các phác thảo sơ đồ ER và bắt đầu soạn sơ bộ các schema cơ sở dữ liệu + Phân công chính thức người phụ trách lead cho từng microservice để tinh giản quá trình phát triển 09/15/2025 09/15/2025 3 - Thiết lập AWS Budgets: + Xem lại các loại budget (Cost, Usage, RI, v.v.) + Định nghĩa ngưỡng chi phí hàng tháng + Cấu hình budget trong AWS Console + Thiết lập cảnh báo email/SNS - Tạo web app nhỏ dùng AWS Lambda: + Tìm hiểu Lambda và cơ bản về function URL + Viết hàm \u0026ldquo;Hello World\u0026rdquo; đơn giản + Cấu hình hàm và IAM role tương ứng + Kích hoạt và kiểm thử endpoint function URL - Thử nghiệm FastAPI cho microservice: + Thực hành theo tutorial FastAPI chính thức + Thiết lập môi trường phát triển local + Xây dựng API proof-of-concept + Triển khai và thử nghiệm các endpoint qua Swagger UI 09/16/2025 09/16/2025 AWS Lambda: https://ap-southeast-1.console.aws.amazon.com/lambda AWS Budgets: https://us-east-1.console.aws.amazon.com/costmanagement/ FastAPI: https://www.coursera.org/learn/packt-mastering-rest-apis-with-fastapi-1xeea/ 4 - Tìm hiểu các kiến thức cơ bản về mạng và bảo mật trên AWS + Ôn lại khái niệm Amazon VPC như một vùng mạng cô lập trong AWS + Hiểu vai trò của subnet và phân biệt subnet public vs private để cấu trúc mạng + Nắm mục đích của Internet Gateway (IGW) để cung cấp truy cập internet cho subnet public và NAT Gateway để cho subnet private truy cập internet một cách an toàn + Khám phá VPC Flow Logs như công cụ giám sát và gỡ lỗi lưu lượng mạng trong VPC + So sánh các phương án kết nối on-premise tới AWS: Site-to-Site VPN (mã hóa qua internet) và Direct Connect (kết nối riêng, private) + Hiểu các trường hợp sử dụng VPC Peering (kết nối trực tiếp giữa hai VPC) so với Transit Gateway + Nắm khái niệm Elastic Load Balancing (ELB) để phân phối traffic giữa nhiều server nhằm tăng tính sẵn sàng 09/17/2025 09/17/2025 Module 02-(01 to 03): https://www.youtube.com/watch?v=O9Ac_vGHquM https://www.youtube.com/watch?v=BPuD1l2hEQ4 https://www.youtube.com/watch?v=CXU8D3kyxIc 5 - Khám phá Amazon Bedrock playground: + Xem các foundation model có sẵn (ví dụ: Claude, Titan) + Chọn model ứng viên để sinh văn bản + Thực nghiệm với các prompt và tham số khác nhau + Sinh và phân tích mẫu phản hồi - Prototype microservice được chỉ định: + Thiết kế logic dịch vụ và tích hợp nhiều API để sinh văn bản + Triển khai các hàm tạo câu ngẫu nhiên và chức năng chat + Đánh giá những hạn chế ban đầu của bản dựng và liệt kê bước tiếp theo để cải tiến + Xác thực phương án kỹ thuật đã chọn 09/18/2025 09/18/2025 Amazon Bedrock:https://ap-southeast-1.console.aws.amazon.com/bedrock 6 - Khởi tạo và cấu hình Amazon RDS: + Xem xét và chọn engine DB phù hợp với nhu cầu dự án + Cấu hình các thiết lập chính cho instance, bao gồm credentials, VPC và security group rules + Khởi tạo DB, theo dõi quá trình tạo và lưu trữ an toàn endpoint kết nối - Prototype TextService dựa trên DB: + Thiết kế schema đơn giản với bảng lưu từ và câu để chứa nội dung văn bản + Viết script một lần để populate dữ liệu khởi tạo vào RDS + Refactor TextService để truy vấn dữ liệu từ DB thay vì gọi API bên ngoài và thực hiện benchmark cải thiện hiệu năng + Chạy benchmark so sánh thời gian phản hồi giữa phương pháp trước (API) và phương pháp mới (DB) 09/19/2025 09/19/2025 Aurora and RDS: https://ap-southeast-1.console.aws.amazon.com/rds Thành tựu Tuần 2: Đã xác định phạm vi cho trò chơi gõ chữ đầu tiên: Tính năng cốt lõi Ranh giới microservice Backlog đã được seed Phân công ownership. Công thức chuẩn cho WPM và accuracy đã được nghiên cứu và ghi chép. Repository chung đã được khởi tạo với cấu trúc đa ngôn ngữ cơ bản. Sơ đồ ER được hoàn thiện và sơ bộ schema quan hệ đã được soạn thảo. Prototype FastAPI đã được giao (sinh văn bản, ghép câu, chat) và kiểm chứng qua Swagger UI. AWS Budgets được cấu hình với ngưỡng hàng tháng và cảnh báo. Nắm vững nền tảng AWS cốt lõi: Lambda (function URL) VPC (subnet, IGW, NAT, Flow Logs) Peering vs Transit Gateway Khái niệm cân bằng tải Đã khảo sát Amazon Bedrock và xác nhận model ứng viên cùng chiến lược prompt. Instance RDS được khởi tạo, schema tạo xong và dataset seed đã được nạp. TextService được refactor sang truy xuất từ DB và ghi nhận cải thiện hiệu năng ban đầu qua benchmark. Đã giới thiệu các thực hành vận hành sớm: phân công vai trò, tập trung benchmark và cân nhắc khả năng mở rộng. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/4.3-event3/",
	"title": "Tái định hình DevOps với AWS Generative AI",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch Mục tiêu Sự kiện Chia sẻ bối cảnh hiện tại của DevOps và tác động của Generative AI. Trình bày các case study thực tế và framework triển khai AI vào DevOps. Cung cấp live demo về các công cụ AWS Generative AI giúp tăng cường development lifecycle. Thảo luận vai trò đang thay đổi của DevOps engineers và các kỹ năng cần có trong tương lai. Diễn giả Lê Thanh Đức – Cloud Delivery Manager, CMC Global Dư Quốc Thành – Technical Leader, CMC Global Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Những điểm nhấn chính Tiến hóa từ DevOps đến DevSecOps Tư duy DevOps hiện đại tích hợp security ngay từ đầu, biến nó thành trách nhiệm chung giữa development, security và operations. Chuyển từ security kiểu phản ứng sau phát triển sang cách tiếp cận chủ động, nơi security được nhúng trong mọi phase. Sự chuyển đổi văn hóa này là cốt lõi của DevSecOps, nhằm cân bằng tốc độ phát triển với bảo mật hệ thống. Các Giai đoạn của Secure DevOps Lifecycle Một cách tiếp cận 7 giai đoạn để nhúng security xuyên suốt pipeline:\nPlan: Xác định security requirements và thực hiện threat modeling. Code: Dùng static analysis (SAST) để phát hiện vulnerabilities sớm. Build: Tự động hóa security checks, dependency scans và configuration validation. Test: Tích hợp penetration testing và compliance auditing. Deploy: Scan Infrastructure as Code (IaC) để đảm bảo môi trường an toàn. Operate: Tự động hóa patching, incident response và remediation. Monitor: Sử dụng real-time analytics và AI-powered anomaly detection để phòng thủ chủ động. Khai thác AI trong DevOps Toolchain Automation: AI tự động hóa các tác vụ lặp lại như code review, log analysis, vulnerability scanning và lọc false positives. Enhanced Security: Công cụ AI-driven có thể ưu tiên rủi ro trọng yếu, gợi ý cách fix và phát hiện hành vi bất thường trong runtime environments. Efficiency: AI hỗ trợ tạo documentation, reports và compliance policies, giảm tải thủ công. Tooling Examples: Phiên chia sẻ nêu các tools như SonarQube, Checkov, Prometheus và GitHub Actions, cùng vai trò của AI trong việc tăng cường khả năng của chúng. Công cụ AWS cho AI-Enhanced DevOps Amazon CodeGuru: Dịch vụ demo để scan code tìm vulnerabilities (ví dụ: SQL injection, secret leaks) và đưa ra actionable recommendations để fix. AWS Managed Control Plane (MCP) \u0026amp; Base (MCB): Công cụ tự động hóa security compliance và updates cho Terraform và Kubernetes (EKS) configurations. Cost Optimization: Các dịch vụ AI/ML như AWS Cost Anomaly Detection và Compute Optimizer giúp dự đoán nhu cầu tài nguyên và giảm lãng phí. Bài học Chính Tư duy Bảo mật Proactive Integration: Luôn bắt đầu với security, nhúng nó vào giai đoạn sớm nhất của planning và development, không phải thêm vào sau. Shared Responsibility: Xây dựng văn hóa nơi developers, operations và security cùng chịu trách nhiệm về security. Continuous Improvement: Dùng feedback loops từ monitoring và incidents để liên tục cải thiện quy trình bảo mật. Kiến trúc Kỹ thuật Automated Security Pipeline: Nhúng automated security checks ở mọi stage của CI/CD pipeline, từ code scanning đến deployment. Observability: Triển khai monitoring, logging và alerting mạnh (ví dụ: Prometheus, Grafana, Loki) để có real-time insights về sức khỏe và bảo mật hệ thống. IaC Security: Sử dụng công cụ scan IaC configurations để ngăn misconfigurations trước khi lên production. Chiến lược Tích hợp AI Phased Approach: Lựa chọn và áp dụng AI tools phù hợp nhu cầu dự án để tránh overhead và độ phức tạp không cần thiết. Human-in-the-Loop: Xem AI như trợ lý mạnh mẽ để tăng cường năng lực con người, không phải thay thế. Sự giám sát và phán đoán của con người vẫn là then chốt. Measure ROI: Đo lường hiệu quả tích hợp AI qua tốc độ phát triển, cải thiện security posture và giảm nỗ lực thủ công. Ứng dụng vào Công việc Nâng cấp CI/CD: Tích hợp SAST và dependency scanning tự động vào pipeline hiện tại. Áp dụng IaC Scanning: Dùng công cụ như Checkov để validate Terraform hoặc các IaC scripts khác. Pilot AWS AI Tools: Thử nghiệm Amazon CodeGuru trên một dự án nhỏ để review code quality và security. Cải thiện Monitoring: Tận dụng AI-powered anomaly detection để nhận cảnh báo chủ động về vấn đề tiềm ẩn. Tự động hóa Tài liệu: Dùng AI hỗ trợ tạo và duy trì project documentation và reports. Trải nghiệm Sự kiện Tham dự buổi \u0026ldquo;Reinventing DevOps with AWS Generative AI\u0026rdquo; rất giá trị, cung cấp cái nhìn toàn diện về cách AI đang tái định hình bảo mật và hiệu suất trong phát triển phần mềm. Một số trải nghiệm chính:\nHọc hỏi từ các diễn giả giàu kinh nghiệm Các chuyên gia từ CMC Global và AWS Vietnam chia sẻ hiểu biết sâu sắc từ kinh nghiệm rộng về cloud và DevOps. Qua các case study thực tế từ khách hàng ở Philippines và Singapore, tôi hiểu rõ hơn cách triển khai secure CI/CD pipelines. Trải nghiệm kỹ thuật hands-on Live demo của Amazon CodeGuru đặc biệt ấn tượng, cho thấy cách AI có thể xác định vulnerabilities và gợi ý code fixes theo thời gian thực. Tận dụng công cụ hiện đại Khám phá DevOps toolchain hiện đại gồm SonarQube, Checkov, Prometheus và GitLab CI, và hiểu cách AI tích hợp cùng chúng. Học cách dùng AI cho infrastructure management và compliance với các công cụ như AWS MCP và MCB. Kết nối và thảo luận Phiên Q\u0026amp;A tương tác cho phép đào sâu các chủ đề như tiến hóa vai trò DevOps, giới hạn của AI và định hướng nghề nghiệp cho cloud architects. Các thảo luận củng cố tầm quan trọng của việc cân bằng giữa AI automation và chuyên môn con người cùng tư duy phản biện. Bài học rút ra Dịch chuyển sang văn hóa DevSecOps là thiết yếu để xây dựng ứng dụng an toàn và tin cậy với tốc độ cao. Công cụ AI như Amazon CodeGuru có thể tăng mạnh năng suất và bảo mật, nhưng vẫn cần human oversight để xác minh và áp dụng đề xuất hiệu quả. Hiện đại hóa cần chiến lược rõ ràng; tiếp cận theo phases khi áp dụng công cụ và quy trình mới sẽ ít rủi ro và hiệu quả hơn. Tổng thể, sự kiện không chỉ mang lại kiến thức kỹ thuật mà còn tái định hình tư duy của tôi về tương lai DevOps, vai trò không thể thiếu của bảo mật tích hợp, và tiềm năng hợp tác giữa AI và kỹ sư con người.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của Tuần 3: Hoàn thành các lab AWS quan trọng, bao gồm Site-to-Site VPN và các thao tác cơ bản với EC2. Học và hoàn thành đầy đủ bốn module của khóa AWS Cloud Technical Essentials. Nâng cao kỹ năng sử dụng AWS Console và AWS CLI (quản lý credential, key pairs, khám phá region và service). Phối hợp với đội product/design để phân tích và ghi chú UI/UX của TypeRush từ bản thiết kế Figma. Đánh giá các phương án lưu trữ và đưa ra quyết định sử dụng NoSQL cho TextService. Thử nghiệm tích hợp MongoDB (tạo môi trường, seeding, refactor service, kiểm thử). Xây dựng thói quen trao đổi và cộng tác hiệu quả với team First Cloud Journey. Các công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 - Lab 03: AWS Site-to-Site VPN: + Xây dựng đầy đủ môi trường Site-to-Site VPN gồm VPC mới, EC2 đóng vai Customer Gateway, Virtual Private Gateway và VPN Connection. + Cấu hình và kiểm tra kết nối đường hầm VPN. - Lab 04: Amazon EC2 Fundamentals: + Khởi tạo và kết nối EC2 Windows Server và Amazon Linux. + Triển khai ứng dụng CRUD \u0026ldquo;AWS User Management\u0026rdquo; trên cả Windows và Linux. + Khám phá các tính năng EC2: thay đổi type, quản lý snapshot EBS, tạo custom AMI. 09/22/2025 09/22/2025 VPN Lab (Lab 03): https://000003.awsstudygroup.com/ EC2 Lab (Lab 04): https://000004.awsstudygroup.com/ 3 - Bắt đầu khóa AWS Cloud Technical Essentials và hoàn thành 2 module đầu: + Module 1: Cloud Foundations \u0026amp; IAM - Định nghĩa cloud computing và giá trị của nó. - So sánh workload on-premise và workload trên cloud. - Tạo tài khoản AWS và tìm hiểu các cách tương tác (Console/CLI/SDK). - Tìm hiểu Global Infrastructure (Region, AZ). - Học và áp dụng best practices của IAM. + Module 2: Compute \u0026amp; Networking - Tìm hiểu kiến trúc EC2. - Phân biệt container và virtual machine. - Khám phá serverless và các trường hợp sử dụng. - Tìm hiểu VPC và tạo custom VPC. 09/23/2025 09/23/2025 AWS Cloud Technical Essentials: https://www.coursera.org/learn/aws-cloud-technical-essentials 4 - Phối hợp với team design để tài liệu hóa UI/UX TypeRush: + Tham gia buổi review cross-functional để xem xét toàn bộ flow Figma mới. + Phân tích các màn hình chính (login, game, score, settings) để hiểu bố cục, visual hierarchy và user interaction. + Ghi lại danh sách câu hỏi kỹ thuật và các điểm cần xác thực với design. + Bắt đầu chuyển thiết kế thành yêu cầu component và user stories phục vụ cho sprint sau. - Thảo luận hướng lưu trữ TextService với team lead: + So sánh mô hình lưu trữ SQL và NoSQL dựa trên cấu trúc dữ liệu và cách truy cập. + Trình bày ưu/nhược điểm và case sử dụng. + Chốt sử dụng NoSQL vì linh hoạt và dễ mở rộng. 09/24/2025 09/24/2025 5 - Tích hợp và thử nghiệm MongoDB cho prototype TextService: + Dựng môi trường MongoDB bằng Docker. + Điều chỉnh script seeding để insert tài liệu (words/sentences) vào collection. + Refactor TextService để đọc/ghi qua MongoDB. + Kiểm thử đầy đủ để xác nhận kết nối và luồng dữ liệu hoạt động đúng. 09/25/2025 09/25/2025 6 - Hoàn thành 2 module cuối của AWS Cloud Technical Essentials: + Module 3: Storage \u0026amp; Databases - Phân biệt file storage, block storage và object storage. - Tìm hiểu Amazon S3, tạo S3 bucket. - Tìm hiểu EBS và các dịch vụ database của AWS. - Tạo DynamoDB table. + Module 4: Monitoring \u0026amp; High Availability - Tìm hiểu CloudWatch và các lợi ích khi monitoring. - Học cách tối ưu hiệu suất và chi phí. - Tìm hiểu cơ chế ELB phân phối lưu lượng. - Phân biệt scaling up và scaling out, triển khai mô hình high availability. 09/26/2025 09/26/2025 AWS Cloud Technical Essentials: https://www.coursera.org/learn/aws-cloud-technical-essentials Thành tựu Tuần 3: Hoàn tất các AWS Labs:\nXây dựng Site-to-Site VPN hoàn chỉnh (VPC, EC2 gateway, virtual private gateway, cấu hình tunnel). Hoàn thiện EC2 fundamentals: chạy Windows/Linux, deploy CRUD app, quản lý snapshot, tạo custom AMI. Hoàn thành toàn bộ 4 module của AWS Cloud Technical Essentials\n(Cloud Foundations/IAM, Compute \u0026amp; Networking, Storage \u0026amp; Databases, Monitoring \u0026amp; High Availability).\nNâng cao kỹ năng AWS Console \u0026amp; CLI:\nQuản lý tài khoản, IAM credentials. Điều hướng service/region thành thạo hơn. Thao tác với key pair và các lệnh CLI để kiểm tra tài nguyên. Tài liệu hóa UI/UX TypeRush:\nReview toàn bộ flow trên Figma. Ghi nhận trạng thái component và câu hỏi khả thi kỹ thuật. Soạn các user story và yêu cầu ban đầu. Chiến lược lưu trữ TextService:\nĐánh giá SQL vs NoSQL. Quyết định sử dụng NoSQL để tăng tính linh hoạt và khả năng mở rộng. Prototype MongoDB:\nDựng môi trường Docker. Viết lại script seeding. Refactor service sang MongoDB. Kiểm thử toàn bộ luồng đọc/ghi dữ liệu. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/4.4-event4/",
	"title": "Sự kiện 4",
	"tags": [],
	"description": "",
	"content": " Tên sự kiện: \u0026lt;Thêm tên sự kiện 4\u0026gt;\nNgày \u0026amp; giờ: Địa điểm: \u0026lt;Địa điểm hoặc trực tuyến\u0026gt;\nVai trò: \u0026lt;Vai trò của bạn\u0026gt;\nMô tả:\n\u0026lt;Thêm mô tả ngắn về nội dung và bài học\u0026gt; "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/",
	"title": "Các sự kiện đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong suốt quá trình thực tập, em đã tham gia 5 sự kiện. Mỗi sự kiện là một trải nghiệm đáng nhớ, mang lại những hiểu biết sâu sắc, những bài học giá trị và cơ hội kết nối tuyệt vời.\nKick-off AWS FCJ Workforce Tên sự kiện: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nThời gian: 08:30 ngày 06/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, TP. Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt: Các phiên định hướng chiến lược về lộ trình nghề nghiệp AWS (Cloud, DevOps, AI/ML, Security, Data), bao gồm chia sẻ từ cựu sinh viên, hoạt động networking và hỏi đáp tương tác.\nGiá trị cốt lõi đạt được: Định hình lại tư duy phát triển dài hạn; làm rõ lộ trình DevOps/Cloud; cam kết gắn kết với cộng đồng AWS Builders và chia sẻ kiến thức lại với đội nhóm.\nData Science On AWS Tên sự kiện: Data Science On AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT TP.HCM, Khu Công nghệ cao, TP. Thủ Đức, TP. Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt: Trình diễn quy trình Data Science toàn diện trên AWS (S3 → Glue → SageMaker), bao gồm demo trực tiếp (ETL dữ liệu IMDb, Phân tích cảm xúc) và tổng quan về các dịch vụ AI được quản lý (Transcribe, Comprehend, Rekognition, Personalize).\nGiá trị cốt lõi đạt được: Tiếp thu kỹ năng mới về Glue ETL và huấn luyện/triển khai SageMaker; củng cố tư duy \u0026ldquo;data-first\u0026rdquo;; đóng góp vào việc tự động hóa quy trình ETL, thử nghiệm mô hình phân tích cảm xúc và tinh gọn quy trình MLOps.\nReinventing DevOps with AWS Generative AI Tên sự kiện: Reinventing DevOps with AWS Generative AI\nThời gian: 19:30 ngày 16/10/2025\nĐịa điểm: Online qua Microsoft Teams (Tổ chức bởi CMC Global)\nVai trò: Người tham dự\nTóm tắt: Chuyển đổi từ DevOps sang DevSecOps sử dụng vòng đời bảo mật 7 pha và chuỗi công cụ hỗ trợ bởi AI (bao gồm demo Amazon CodeGuru), nhấn mạnh vào bảo mật IaC và khả năng quan sát (observability).\nGiá trị cốt lõi đạt được: Làm chủ kỹ năng quét SAST/dependency, quét bảo mật IaC (ví dụ: Checkov), và phát hiện bất thường bằng AI; đóng góp bằng cách triển khai các chốt chặn bảo mật (security gates) trong CI/CD, thử nghiệm CodeGuru và cải thiện tài liệu giám sát.\nGenerative AI with Amazon Bedrock Tên sự kiện: Generative AI with Amazon Bedrock\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, TP. Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt: Tổng quan cấp cao về Generative AI trên AWS sử dụng Amazon Bedrock và các Foundation Models. Bao gồm kỹ thuật Prompt Engineering nâng cao (Zero-Shot, Few-Shot, Chain-of-Thought), triển khai RAG với Amazon Titan và cơ sở dữ liệu vector, cùng giới thiệu về Agentic AI và Amazon Bedrock AgentCore cho các agent sẵn sàng production.\nGiá trị cốt lõi đạt được: Hiểu rõ cách kiến trúc ứng dụng tích hợp RAG, tối ưu hóa thiết kế prompt và đưa các nguyên mẫu AI lên môi trường production an toàn, có khả năng mở rộng. Xác định các bước tiếp theo sử dụng aws-samples và Bedrock_AgentCore để xây dựng trợ lý AI nội bộ dựa trên dữ liệu riêng.\nDevOps on AWS Tên sự kiện: DevOps on AWS\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, TP. Hồ Chí Minh\nVai trò: Người tham dự\nTóm tắt: Thực hành DevOps toàn diện trên AWS: Cơ sở hạ tầng dưới dạng mã (IaC) qua CloudFormation và CDK; đường ống CI/CD sử dụng bộ công cụ CodeSuite; Container hóa với Docker và hệ sinh thái AWS (ECR, ECS, EKS, Fargate, App Runner); và Giám sát qua CloudWatch và X-Ray.\nGiá trị cốt lõi đạt được: Củng cố tư duy DevOps và kỹ năng thực tiễn để thay thế thao tác thủ công \u0026ldquo;ClickOps\u0026rdquo; bằng IaC tự động, chuẩn hóa quy trình CI/CD và áp dụng kiến trúc ưu tiên container (container-first) cho microservices. Các hành động cụ thể bao gồm mã hóa hạ tầng hiện có, container hóa ứng dụng và nâng cao khả năng quan sát với dashboard và traces tùy chỉnh.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 4: Nắm vững cấu hình Amazon RDS, bao gồm thiết lập VPC, security group và quản lý backup. Học triển khai ứng dụng web có khả năng mở rộng bằng Auto Scaling Group và Application Load Balancer. Củng cố kỹ năng giám sát với CloudWatch: metrics, logs, alarms và dashboard tùy chỉnh. Tìm hiểu mô hình DNS lai sử dụng Route 53 Resolver trong môi trường doanh nghiệp. Thành thạo AWS CLI để quản lý tài nguyên S3, EC2, VPC và IAM. Xây dựng pipeline CI/CD hoàn chỉnh với CodeCommit, CodeBuild, CodeDeploy và CodePipeline. Thiết lập chiến lược backup tự động bằng AWS Backup và lifecycle policy. Triển khai ứng dụng container với Docker và container registry trên AWS. Tìm hiểu quy trình di chuyển máy ảo (VM) gồm import và export giữa các môi trường. Xây dựng ứng dụng serverless bằng AWS Lambda và API Gateway. Hiểu hệ thống giám sát bảo mật tập trung bằng AWS Security Hub. Các nhiệm vụ đã hoàn thành trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu tham khảo 2 - Cấu hình và quản lý Amazon RDS: + Thiết lập VPC, security group và DB subnet group + Tạo EC2 và RDS instance + Deploy ứng dụng mẫu kết nối RDS + Thực hiện backup và restore + Dọn dẹp tài nguyên - Triển khai ứng dụng có khả năng mở rộng: + Cấu hình VPC, subnet và security group + Tạo Launch Template + Tạo Target Group và ALB + Tạo Auto Scaling Group với chính sách manual / scheduled / dynamic + Dọn tài nguyên - Giám sát với CloudWatch: + Phân tích metrics bằng search và math expression + Query logs bằng Logs Insights + Tạo Metric Filter + Tạo Alarm + Xây dashboard + Xóa alarms và dashboards 29/09/2025 29/09/2025 RDS, Auto Scaling, CloudWatch Labs 3 - Triển khai DNS lai với Route 53 Resolver: + Deploy hạ tầng bằng CloudFormation + Tạo Microsoft AD mô phỏng DNS on-prem + Tạo outbound \u0026amp; inbound endpoint + Cấu hình rule chuyển tiếp DNS + Kiểm tra phân giải 2 chiều và dọn tài nguyên - Quản lý AWS bằng CLI: + Cài đặt và cấu hình AWS CLI + Quản lý S3, SNS, IAM bằng CLI + Thao tác bucket và object + Tạo và quản lý VPC bằng CLI + Tạo và xoá EC2 bằng CLI + Dọn tài nguyên 30/09/2025 30/09/2025 Route 53 Resolver, AWS CLI Labs 4 - Xây dựng pipeline CI/CD tự động: + Tạo repo CodeCommit + Cấu hình CodeBuild để build và package app + Tạo CodeDeploy để tự động deploy + Dùng CodePipeline để điều phối toàn bộ quy trình + Test bằng cách push code + Dọn tài nguyên - Tự động hóa backup EC2 bằng AWS Backup: + Deploy hạ tầng bằng CloudFormation + Tạo backup plan với lifecycle policy + Cấu hình thông báo backup + Test backup \u0026amp; restore + Xoá stack và backup 01/10/2025 01/10/2025 CodePipeline, AWS Backup Labs 5 - Triển khai ứng dụng Docker trên AWS: + Tạo VPC, security group, IAM role + Tạo RDS instance + Deploy ứng dụng bằng Docker image + Triển khai lại bằng Docker Compose + Push image lên ECR / Docker Hub + Xóa tài nguyên - Di chuyển máy ảo (VM Import/Export): + Export VM từ on-prem + Upload image lên S3 + Import thành AMI + Tạo EC2 từ AMI + Export EC2 trở lại S3 + Xóa toàn bộ 02/10/2025 02/10/2025 Docker on AWS, VM Import/Export Labs 6 - Triển khai ứng dụng serverless: + Chuẩn bị package Lambda + Tạo IAM role cho Lambda + Deploy Lambda function + Tạo HTTP API và tích hợp Lambda + Deploy và test endpoint + Xóa API, Lambda, IAM role - Giám sát bảo mật tập trung với Security Hub: + Enable Security Hub + Xem dashboard và findings + Phân tích phát hiện từ GuardDuty, Inspector, Macie + Xem biểu đồ rủi ro 03/10/2025 03/10/2025 Lambda \u0026amp; Security Hub Labs Thành tựu Tuần 4: Cấu hình thành công Amazon RDS cùng toàn bộ networking và backup. Xây dựng hạ tầng Auto Scaling + ALB cho ứng dụng mở rộng. Hoàn thiện giám sát CloudWatch với metrics, logs, alarms, dashboards. Cấu hình DNS lai với Route 53 Resolver + Microsoft AD. Thành thạo AWS CLI cho nhiều dịch vụ khác nhau. Xây dựng pipeline CI/CD tự động đầy đủ. Thiết lập backup tự động theo lifecycle với AWS Backup. Deploy ứng dụng Docker và publish image lên ECR. Hoàn tất quy trình di chuyển VM import/export. Xây dựng ứng dụng serverless với Lambda + API Gateway. Giám sát bảo mật tập trung bằng Security Hub. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/4-eventparticipated/4.5-event5/",
	"title": "DevOps trên AWS",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch Mục tiêu Sự kiện Xây dựng tư duy DevOps, bao quát văn hóa, các nguyên tắc và những chỉ số hiệu năng quan trọng. Đi sâu vào cách xây dựng CI/CD pipelines sử dụng các AWS DevOps services native. Giới thiệu các nguyên tắc Infrastructure as Code (IaC) với AWS CloudFormation và AWS CDK. Khám phá hệ sinh thái container trên AWS, bao gồm Docker, Amazon ECR, ECS, EKS và App Runner. Minh họa cách triển khai monitoring và observability toàn diện sử dụng CloudWatch và AWS X-Ray. Diễn giả Truong Quang Tinh - Platform Engineer (TymeX), AWS Community Builder Bao Huynh - AWS Community Builder Thinh Nguyen - AWS Community Builder Vi Tran - AWS Community Builder Van Hoang Kha – Cloud Engineer, AWS Community Builder Long Huynh - AWS Community Builder Quy Pham - AWS Community Builder Nghiem Le - AWS Community Builder Những điểm nhấn chính Từ Manual Operations đến Infrastructure as Code (IaC) Workshop nhấn mạnh những hạn chế của \u0026ldquo;ClickOps\u0026rdquo; (quản lý thủ công qua console), như chậm, dễ lỗi và khó tái lập. AWS CloudFormation: Được giới thiệu như giải pháp IaC native trên AWS, sử dụng YAML/JSON template để định nghĩa và quản lý AWS resources theo dạng \u0026ldquo;Stacks\u0026rdquo; và có khả năng phát hiện configuration drift. AWS Cloud Development Kit (CDK): Được trình bày như một framework IaC thân thiện với developer, cho phép định nghĩa hạ tầng bằng các ngôn ngữ lập trình quen thuộc (ví dụ: Python, TypeScript), sử dụng các \u0026ldquo;Constructs\u0026rdquo; tái sử dụng để tăng tốc phát triển. Xây dựng CI/CD Pipeline Hoàn Chỉnh Một pipeline tự động, end‑to‑end được demo sử dụng bộ AWS developer tools: AWS CodeCommit: Dùng cho secure source control. AWS CodeBuild: Dùng cho automated builds và testing. AWS CodeDeploy: Dùng để quản lý các chiến lược deploy phức tạp như Blue/Green và Canary releases. AWS CodePipeline: Dùng để orchestrate toàn bộ release process từ source đến deployment. Containerization và Orchestration Phiên chia sẻ bao quát fundamentals của containerization với Docker và tầm quan trọng của container registry như Amazon ECR để lưu trữ và scan images. Một phần so sánh chi tiết giữa các dịch vụ orchestration được trình bày: Amazon ECS: Dịch vụ native trên AWS, đơn giản hơn, tích hợp sâu với hệ sinh thái AWS, phù hợp với các team muốn giảm tối đa operational overhead. Amazon EKS: Dịch vụ managed Kubernetes tuân theo chuẩn open‑source, mang lại tính linh hoạt cao và khả năng multi‑cloud portability, nhưng đi kèm độ phức tạp vận hành lớn hơn. AWS Fargate \u0026amp; App Runner: Các tùy chọn serverless compute giúp không cần quản lý servers bên dưới cho containers, đơn giản hóa việc deploy và vận hành. Monitoring và Observability Tầm quan trọng của full‑stack observability được nhấn mạnh để vận hành và debug các distributed systems. Amazon CloudWatch: Được dùng để thu thập metrics, logs và thiết lập alarms, dashboards. AWS X-Ray: Được demo cho distributed tracing nhằm phân tích và debug performance bottlenecks trong microservices architectures. Bài học Chính (Key Takeaways) Tư duy Thiết kế (Design Mindset) Automate Everything: Chuyển từ \u0026ldquo;ClickOps\u0026rdquo; thủ công sang cách tiếp cận IaC tự động hóa hoàn toàn để đảm bảo tính nhất quán, tốc độ và độ tin cậy. Infrastructure as Code is Non‑Negotiable: IaC là nền tảng của DevOps hiện đại, cho phép cộng tác, versioning và tái lập môi trường một cách dễ dàng. Choose the Right Tool for the Team: Việc lựa chọn giữa CloudFormation, CDK, ECS và EKS cần dựa trên kỹ năng team, nhu cầu hệ sinh thái và mức độ cân bằng mong muốn giữa đơn giản và quyền kiểm soát. Kiến trúc Kỹ thuật (Technical Architecture) CI/CD Pipelines: Mỗi project nên có một automated pipeline để xử lý code integration, testing và deployment, đảm bảo release nhanh và an toàn. Container‑First cho Microservices: Sử dụng containers để đóng gói ứng dụng và dependencies, cùng với một orchestrator (ECS hoặc EKS) để quản lý ở quy mô lớn. Full‑Stack Observability: Xây dựng chiến lược monitoring mạnh với metrics, logs (CloudWatch) và distributed tracing (X‑Ray) để có cái nhìn sâu về performance và sức khỏe ứng dụng. Chiến lược Hiện đại hóa (Modernization Strategy) Phased Adoption: Áp dụng DevOps một cách tuần tự. Bắt đầu bằng việc chuyển đổi một quy trình thủ công sang IaC hoặc xây dựng một CI/CD pipeline cho một service duy nhất. Leverage Serverless: Tận dụng các tùy chọn serverless như AWS Fargate và App Runner để giảm độ phức tạp vận hành và cho phép team tập trung vào application logic thay vì quản lý hạ tầng. Measure What Matters: Tập trung vào các DevOps metrics quan trọng như Deployment Frequency, Lead Time for Changes và Mean Time to Recovery (MTTR) để thúc đẩy cải tiến liên tục. Ứng dụng vào Công việc Tự động hóa một Deployment: Chuyển một ứng dụng đang deploy thủ công sang sử dụng AWS CodePipeline workflow. Mã hóa Hạ tầng (Codify Infrastructure): Định nghĩa một S3 bucket hoặc EC2 instance hiện có bằng một AWS CloudFormation template hoặc một ứng dụng CDK. Containerize một Ứng dụng: Tạo Dockerfile cho một web application và push image đó lên Amazon ECR. Thử nghiệm Container Service: Deploy một ứng dụng container hóa đơn giản bằng AWS App Runner hoặc ECS với Fargate launch type. Cải thiện Observability: Tạo một CloudWatch Dashboard cho một ứng dụng quan trọng và cấu hình alarms cho các metrics then chốt như CPU utilization và error rates. Trải nghiệm Sự kiện Tham dự workshop \u0026ldquo;DevOps on AWS\u0026rdquo; mang lại giá trị rất lớn, cung cấp một hướng dẫn toàn diện và thực tiễn về cách triển khai DevOps hiện đại trên nền tảng cloud.\nHọc hỏi từ các diễn giả giàu kinh nghiệm Các AWS Community Builders chia sẻ kiến thức sâu sắc, thực tiễn, giúp chia nhỏ các chủ đề phức tạp thành những khái niệm dễ hiểu. Trải nghiệm kỹ thuật hands‑on Nhiều live demo, bao gồm walkthrough một CI/CD pipeline hoàn chỉnh và deployment microservices trên ECS, giúp tôi thấy rõ ngữ cảnh thực tế cho các công cụ và dịch vụ được giới thiệu. Tận dụng công cụ hiện đại Workshop cung cấp cái nhìn đầy đủ về bộ AWS DevOps toolkit hiện đại, từ IaC nâng cao với CDK đến serverless containers với App Runner. Kết nối và thảo luận Phiên Q\u0026amp;A tạo cơ hội trao đổi về lộ trình nghề nghiệp và AWS certification roadmap, mang lại định hướng giá trị cho phát triển chuyên môn. Bài học rút ra Việc áp dụng IaC là bước đòn bẩy quan trọng nhất để đạt đến một thực hành DevOps trưởng thành. AWS cung cấp một bộ công cụ tích hợp, đầy đủ để xây dựng một DevOps platform hiện đại, với các lựa chọn phù hợp cho đội ngũ ở nhiều quy mô và mức kỹ năng khác nhau. Monitoring và observability hiệu quả không phải là tùy chọn; chúng là yếu tố bắt buộc để vận hành các ứng dụng cloud đáng tin cậy và hiệu năng cao. Một số hình ảnh sự kiện "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 5: Triển khai các kỹ thuật networking nâng cao với VPC Peering và Transit Gateway để kết nối nhiều VPC. Deploy ứng dụng full-stack sử dụng EC2, RDS, Auto Scaling và tích hợp CloudFront. Xây dựng giải pháp tối ưu chi phí bằng serverless với AWS Lambda để tự động quản lý EC2. Thiết lập pipeline CI/CD bằng bộ công cụ AWS Developer Tools cho quá trình deploy tự động. Cấu hình hybrid cloud storage bằng AWS Storage Gateway để kết nối môi trường on-premises. Quản lý hệ thống file doanh nghiệp bằng Amazon FSx và tăng cường bảo mật web bằng AWS WAF. Tổ chức tài nguyên AWS hiệu quả với Tags và Resource Groups. Nâng cao kỹ năng thao tác bằng cả AWS Management Console và AWS CLI. Nhiệm vụ đã thực hiện trong tuần: Ngày Công việc Bắt đầu Hoàn thành Tài liệu tham khảo 2 - Thiết lập VPC Peering giữa hai VPC:\n+ Khởi tạo môi trường bằng CloudFormation\n+ Tạo Security Group cho EC2\n+ Khởi tạo EC2 ở từng VPC để kiểm tra kết nối\n+ Cập nhật Network ACLs\n+ Tạo \u0026amp; chấp nhận kết nối Peering\n+ Cấu hình Route Tables để định tuyến\n+ Bật Cross-Peer DNS để resolve tên miền\n- Triển khai kiến trúc mạng mở rộng với Transit Gateway:\n+ Tạo Key Pair\n+ Khởi tạo môi trường bằng CloudFormation\n+ Tạo Transit Gateway làm trung tâm kết nối\n+ Gắn các VPC vào Transit Gateway\n+ Cấu hình Transit Gateway Route Tables\n+ Cập nhật Route Tables của VPC 10/06/2025 10/06/2025 VPC Peering: https://000019.awsstudygroup.com/ Transit Gateway: https://000020.awsstudygroup.com/ 3 - Triển khai WordPress trên AWS:\n+ Chuẩn bị VPC/Subnet\n+ Tạo Security Group cho EC2 và RDS\n+ Tạo EC2 host WordPress\n+ Tạo RDS cho database\n+ Cài đặt và cấu hình WordPress\n+ Thiết lập Auto Scaling\n+ Thực hiện backup/restore database\n+ Tích hợp CloudFront để tăng tốc hiệu năng\n- Tối ưu chi phí EC2 bằng Lambda:\n+ Gắn tags cho EC2 để quản lý chi phí\n+ Tạo IAM Role cho Lambda\n+ Viết Lambda tự động tắt/bật EC2\n+ Kiểm thử hoạt động của Lambda 10/07/2025 10/07/2025 WordPress: https://000021.awsstudygroup.com/ Lambda Optimization: https://000022.awsstudygroup.com/ 4 - Tự động hoá triển khai ứng dụng với CI/CD Pipeline:\n+ Chuẩn bị tài nguyên cần thiết\n+ Cài đặt CodeDeploy Agent lên EC2\n+ Tạo repo CodeCommit lưu mã nguồn\n+ Cấu hình CodeBuild để build ứng dụng\n+ Thiết lập CodeDeploy để deploy tự động\n+ Xây dựng CodePipeline orchestrate toàn bộ pipeline\n+ Xử lý lỗi trong quá trình chạy pipeline\n- Sử dụng Storage Gateway cho hybrid cloud:\n+ Tạo S3 Bucket\n+ Tạo EC2 host Storage Gateway\n+ Khởi tạo Storage Gateway\n+ Tạo File Shares\n+ Mount File Shares trên máy on-premises 10/08/2025 10/08/2025 CI/CD: https://000023.awsstudygroup.com/ Storage Gateway: https://000024.awsstudygroup.com/ 5 - Quản lý Amazon FSx for Windows File Server:\n+ Tạo môi trường\n+ Tạo file system SSD và HDD Multi-AZ\n+ Tạo file shares\n+ Kiểm thử hiệu năng\n+ Bật Data Deduplication \u0026amp; Shadow Copies\n+ Quản lý sessions, open files, quotas\n+ Bật Continuous Access share\n+ Scale throughput và storage\n+ Xoá môi trường khi hoàn tất\n+ Tham khảo AWS CLI để quản lý FSx\n- Triển khai AWS WAF:\n+ Tạo S3 bucket và deploy web mẫu\n+ Sử dụng Managed Rules\n+ Tạo Custom Rules nâng cao\n+ Kiểm thử rule\n+ Bật logging\n+ Cleanup tài nguyên 10/09/2025 10/09/2025 Amazon FSx: https://000025.awsstudygroup.com/ AWS WAF: https://000026.awsstudygroup.com/ 6 - Quản lý tài nguyên bằng Tags \u0026amp; Resource Groups:\n+ Hiểu và sử dụng tags trên Console\n+ Tạo EC2 với tags\n+ Thêm/xoá tags trên resource\n+ Lọc tài nguyên theo tags\n+ Sử dụng tags với AWS CLI\n+ Gắn tags cho EC2 qua CLI\n+ Gắn tags khi tạo mới tài nguyên bằng CLI\n+ Liệt kê tài nguyên có tag bằng CLI\n+ Tạo Resource Group dựa trên tags\n+ Quản lý tài nguyên trong Resource Group 10/10/2025 10/10/2025 Tags \u0026amp; Resource Groups: https://000027.awsstudygroup.com/ Thành tựu Tuần 5: Hoàn thiện networking nâng cao trên AWS:\nVPC Peering giúp kết nối trực tiếp giữa các VPC Transit Gateway làm trung tâm kết nối toàn hệ thống Cấu hình routing và DNS giữa nhiều VPC Deploy và tối ưu ứng dụng cloud:\nWordPress tích hợp RDS Auto Scaling + CloudFront tăng hiệu năng và tính sẵn sàng Lambda tối ưu chi phí EC2 tự động Xây dựng quy trình DevOps hoàn chỉnh:\nPipeline CI/CD đầy đủ với CodeCommit – CodeBuild – CodeDeploy – CodePipeline Tự động hoá triển khai Hybrid storage bằng Storage Gateway Quản lý hệ thống file và bảo mật ở cấp doanh nghiệp:\nFSx Multi-AZ, quản lý quotas, deduplication AWS WAF với quản lý rule nâng cao Áp dụng chiến lược quản trị tài nguyên hiệu quả:\nTối ưu chi phí \u0026amp; quản lý bằng Tags Quản lý tài nguyên tập trung bằng Resource Groups Thao tác chuyên sâu bằng Console \u0026amp; CLI Trải nghiệm thực tế với Infrastructure as Code thông qua CloudFormation để tạo môi trường nhất quán.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.6-week6/",
	"title": "Nhật ký công việc Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Học cách quản lý quyền truy cập EC2 bằng IAM, sử dụng tag tài nguyên và permission boundaries. Thiết lập và cấu hình công cụ giám sát như Grafana và AWS CloudWatch. Triển khai AWS Systems Manager để quản lý bản vá và thực thi lệnh từ xa. Tối ưu hóa EC2 bằng thực hành right-sizing và AWS Compute Optimizer. Áp dụng mã hóa cho dữ liệu S3 bằng AWS KMS và cấu hình ghi nhật ký kiểm toán. Phân tích chi phí và mô hình sử dụng AWS bằng Cost Explorer. Xây dựng pipeline và data lake sử dụng S3, Kinesis, Glue, Athena và QuickSight. Tự động hóa provisioning hạ tầng bằng template AWS CloudFormation. Công việc thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Quản lý truy cập dịch vụ EC2 bằng tag tài nguyên thông qua IAM: + Tạo một IAM user để chuẩn bị + Tạo một custom IAM Policy để xác định quyền cụ thể + Thiết lập một IAM Role để user hoặc dịch vụ có thể assume + Kiểm tra policy bằng cách đổi role và thử truy cập - Bắt đầu với Grafana cơ bản: + Tạo VPC và subnet để thiết lập môi trường mạng + Cấu hình Security Group để kiểm soát lưu lượng vào/ra + Khởi chạy một EC2 instance để host ứng dụng giám sát + Tạo IAM User và Role để truy cập an toàn tài nguyên AWS + Gán IAM Role cho EC2 instance + Cài đặt Grafana trên EC2 instance + Thiết lập dashboard giám sát trong Grafana 10/13/2025 10/13/2025 IAM services: https://000028.awsstudygroup.com/ Grafana basic: https://000029.awsstudygroup.com/ 3 - Giới hạn quyền người dùng với IAM Permission Boundary: + Thực hiện các bước chuẩn bị cho bài tập + Tạo một policy hạn chế để định nghĩa quyền lớn nhất được cho phép + Tạo một IAM user mới với quyền bị giới hạn + Kiểm tra giới hạn của IAM user để xác minh permission boundary - Quản lý bản vá và chạy lệnh trên nhiều server bằng AWS Systems Manager: + Tạo VPC và Subnet cho môi trường mạng + Khởi chạy một EC2 Windows công khai + Tạo một IAM Role với quyền cần thiết + Gán IAM Role cho EC2 instance + Cấu hình và sử dụng Patch Manager để quản lý vá + Dùng Run Command để thực thi lệnh trên các server 10/14/2025 10/14/2025 IAM permission boundary: https://000030.awsstudygroup.com/ AWS Systems Manager: https://000031.awsstudygroup.com/ 4 - Thực hiện best practice right-sizing cho Amazon EC2: + Làm quen với Amazon CloudWatch để giám sát + Tạo và gán IAM Role cho CloudWatch Agent + Cài đặt CloudWatch Agent trên EC2 instance + Sử dụng AWS Compute Optimizer để phân tích và tối ưu cấu hình EC2 - Mã hóa dữ liệu lưu trữ tại S3 bằng AWS KMS: + Tạo các IAM policy, role, group và user cần thiết + Thiết lập một KMS key + Tạo bucket S3 và upload dữ liệu + Cấu hình AWS CloudTrail để ghi nhật ký và sử dụng Amazon Athena để truy vấn dữ liệu + Kiểm tra và chia sẻ dữ liệu đã được mã hóa trên S3 10/15/2025 10/15/2025 EC2 right-sizing: https://000032.awsstudygroup.com/ S3 encryption with KMS: https://000033.awsstudygroup.com/ 5 - Trực quan hóa và phân tích chi phí bằng AWS Cost Explorer: + Xem dữ liệu chi phí và sử dụng theo dịch vụ và theo tài khoản + Phân tích phạm vi và hiệu quả của Savings Plans và Reserved Instances + Đánh giá tính co giãn chi phí (cost elasticity) + Tạo báo cáo tùy chỉnh cho các instance EC2 + Dùng Cost Explorer để phân tích chi tiết chi phí + Kiểm tra chi phí truyền dữ liệu cho các kiến trúc phổ biến - Xây dựng data lake trên AWS: + Tạo IAM Role và Policy với quyền cần thiết + Thiết lập bucket S3 để lưu trữ dữ liệu + Tạo Kinesis Data Firehose delivery stream để thu thập dữ liệu + Dùng Glue Crawler để tạo data catalog + Thực hiện chuyển đổi dữ liệu + Phân tích dữ liệu bằng Amazon Athena + Trực quan hóa dữ liệu bằng Amazon QuickSight 10/16/2025 10/17/2025 AWS Cost Explorer: https://000034.awsstudygroup.com/ Data lake on AWS: https://000035.awsstudygroup.com/ 6 - Nghiên cứu AWS CloudWatch cho giám sát và observability: + Khám phá CloudWatch Metrics: xem, tìm kiếm và sử dụng expressions + Làm việc với CloudWatch Logs, Logs Insights và Metric Filters + Cấu hình CloudWatch Alarms để gửi thông báo + Tạo CloudWatch Dashboards để trực quan hóa dữ liệu - Tự động hóa hạ tầng bằng AWS CloudFormation: + Tạo IAM Users và Roles để chuẩn bị + Phát triển template CloudFormation cơ bản để provision tài nguyên + Khám phá các tính năng nâng cao như Custom Resources với Lambda + Sử dụng Mappings, StackSets và Drift Detection cho các triển khai phức tạp 10/17/2025 10/17/2025 AWS CloudWatch: https://000036.awsstudygroup.com/ AWS CloudFormation: https://000037.awsstudygroup.com/ Thành tựu tuần 6: Quản lý truy cập EC2 qua IAM: Cấu hình chính sách truy cập dựa trên tag tài nguyên Áp dụng permission boundaries để giới hạn khả năng của người dùng Thiết lập hệ thống giám sát và observability: Triển khai Grafana trên EC2 để tạo dashboard tùy chỉnh Cấu hình CloudWatch Metrics, Logs và Alarms để giám sát tài nguyên Triển khai khả năng của AWS Systems Manager: Sử dụng Patch Manager để tự động cập nhật bản vá cho server Thực thi lệnh từ xa trên nhiều instance bằng Run Command Ứng dụng tối ưu hóa EC2 và quản lý chi phí: Cài và cấu hình CloudWatch Agent để thu thập metric chi tiết Phân tích cấu hình instance bằng AWS Compute Optimizer Xem xét mẫu chi phí và xu hướng bằng Cost Explorer Bảo mật lưu trữ dữ liệu bằng mã hóa: Tạo và quản lý KMS key cho mã hóa S3 Thiết lập CloudTrail và dùng Athena cho phân tích nhật ký kiểm toán Xây dựng pipeline và data lake: Cấu hình Kinesis Data Firehose để ingest dữ liệu streaming Tạo data catalog bằng Glue Crawler Phân tích dữ liệu bằng Athena và trực quan hóa bằng QuickSight Tự động hóa triển khai hạ tầng bằng CloudFormation: Phát triển template để provisioning tài nguyên Khám phá các tính năng nâng cao như Lambda-backed custom resources và StackSets "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.7-week7/",
	"title": "Nhật ký công việc Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Nâng cao kỹ năng thực hành với Amazon DynamoDB, bao gồm thao tác cơ bản, mô hình dữ liệu nâng cao và kiến trúc đa vùng/toàn cầu. Thiết lập liên kết danh tính (identity federation) và cấu hình IAM roles, đồng thời áp dụng các kỹ thuật tối ưu chi phí giữa AWS và Azure AD. Triển khai và vận hành ứng dụng sử dụng Lightsail, containers, Step Functions và IAM roles để đảm bảo truy cập an toàn. Sử dụng Cloud9, Elastic Beanstalk và công cụ CI/CD để tự động hóa pipeline phân phối ứng dụng. Cải thiện posture bảo mật AWS qua các best practice IAM cơ bản, kiểm soát phát hiện (detective controls), ứng phó sự cố và bảo vệ hạ tầng. Thiết kế và tự động hóa kiến trúc microservices sử dụng Lambda, DynamoDB, Step Functions và CodeStar. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Kiến thức cơ bản về DynamoDB: + Tạo bảng và nạp dữ liệu mẫu + Dùng AWS CLI để đọc/query/scan/insert/update dữ liệu + Kiểm tra dữ liệu bảng và GSI trên Console + Thực hiện backup và restore (PITR và on-demand) - Mẫu thiết kế nâng cao cho DynamoDB: + Xem xét đơn vị dung lượng (RCU/WCU) và hành vi phân vùng + So sánh scan tuần tự và scan song song về hiệu suất + Áp dụng write-sharding cho GSI, key overloading và sparse GSI + Sử dụng composite key và adjacency list cho các truy vấn phức tạp - Capture thay đổi dữ liệu (CDC): + Bật DynamoDB Streams và xử lý các thay đổi + Tạo Lambda để tiêu thụ sự kiện stream + Khám phá CDC với Kinesis Data Streams như phương án thay thế - Ứng dụng serverless toàn cầu với DynamoDB: + Provision các thành phần backend serverless + Cấu hình Global Tables để replicate đa vùng + Tương tác với giao diện mẫu của ứng dụng toàn cầu - Mô hình dữ liệu cho game player: + Thiết kế mô hình dữ liệu dựa trên thực thể và pattern truy cập + Xác định khóa chính và bố cục bảng + Dùng sparse GSI để tìm các game còn trống + Thêm inverted index để lấy lịch sử game của người dùng - Phân tích chi phí \u0026amp; hiệu năng bằng Glue và Athena: + Dựng database bằng Glue Crawlers + Dùng Athena để truy vấn báo cáo chi phí và sử dụng + Áp dụng chiến lược tagging để phân bổ chi phí 10/20/2025 10/20/2025 CDK basic: https://000038.awsstudygroup.com/ Amazon DynamoDB Immersion: https://000039.awsstudygroup.com/ Analysis with Glue and Athena: https://000040.awsstudygroup.com/ 3 - Federation IAM từ Azure AD: + Chuẩn bị Azure AD (tenant, users) + Tạo Enterprise Application trên Azure để kết nối với AWS + Cấu hình Identity Provider và các IAM role tương ứng trên AWS + Đồng bộ roles và cấp quyền truy cập console AWS cho user federated + Kiểm tra đăng nhập từ Azure AD vào AWS Console - Tối ưu chi phí (Savings Plans \u0026amp; RIs): + So sánh Savings Plans và Reserved Instances + Dùng khuyến nghị của AWS để tìm cơ hội tiết kiệm + Mua Savings Plan để giảm chi phí EC2 + Xem xét các loại RI và tùy chọn Reserved DB Instances cho RDS - Chuyển đổi schema \u0026amp; di cư CSDL: + Chuẩn bị EC2 host và cài Schema Conversion Tool (SCT) + Cấu hình DB nguồn (Oracle/SQL Server) và chuyển đổi schema sang định dạng đích + Tạo DMS replication instance, endpoints và task di cư + Thực thi di cư và replicate các thay đổi liên tục + Thử nghiệm DMS Serverless để auto-scaling trong quá trình di cư + Giám sát tiến trình di cư bằng CloudWatch và logs của task - IAM roles \u0026amp; condition policies: + Tạo IAM groups và users + Thiết lập admin role và bật tính năng switch role + Hạn chế sử dụng role theo địa chỉ IP và điều kiện theo thời gian - Triển khai \u0026amp; quản lý ứng dụng trên Lightsail: + Khởi chạy database và WordPress trên Lightsail + Cấu hình mạng và thiết lập ứng dụng + Triển khai Prestashop và Akaunting + Bảo mật ứng dụng, tạo snapshot để backup, nâng cấp kích thước instance và cấu hình alarm 10/21/2025 10/21/2025 IAM Federation with Azure AD: https://000041.awsstudygroup.com/ AWS Cost Optimization: https://000042.awsstudygroup.com/ Database Migration with DMS: https://000043.awsstudygroup.com/ IAM Roles and Conditions: https://000044.awsstudygroup.com/ Amazon Lightsail Applications: https://000045.awsstudygroup.com/ 4 - Lightsail containers: + Tạo dịch vụ container trên Lightsail và deploy image công cộng + Cấp phát một Lightsail instance, cài Docker và AWS CLI + Build, push và deploy image container tùy chỉnh từ instance - AWS Step Functions: + Khởi tạo môi trường Cloud9 và triển khai dịch vụ mẫu + Tạo workflow Step Functions để điều phối Lambda bằng Task states + Thêm nhánh với Choice states, quản lý input/output trạng thái, và dùng Wait tokens + Triển khai xử lý lỗi (retry/catch) và thực thi công việc song song (Parallel) - Cấp quyền ứng dụng bằng IAM roles: + Tạo EC2 instance và bucket S3 cho môi trường thử nghiệm + Minh họa hạn chế khi dùng access key tồn tại lâu dài + Tạo IAM role cho EC2 với quyền truy cập S3 và gắn role vào instance 10/22/2025 10/22/2025 Lightsail Containers: https://000046.awsstudygroup.com/ AWS Step Functions: https://000047.awsstudygroup.com/ IAM Roles for Applications: https://000048.awsstudygroup.com/ 5 - Cloud9 cơ bản: + Tạo môi trường Cloud9 + Sử dụng command line, chỉnh sửa file và chạy AWS CLI trong Cloud9 - Triển khai ứng dụng monolithic lên Elastic Beanstalk: + Thiết lập key pair, CloudFormation stack và database + Cấu hình và truy cập instance, thử nghiệm local bằng Eclipse và deploy lên Beanstalk + Cập nhật ứng dụng và kiểm tra endpoint API - Pipeline release tự động: + Tạo CodeStar project và kết nối Eclipse với CodeCommit + Thay ứng dụng mẫu, kích hoạt pipeline và deploy Windows Service bằng CodeDeploy tới EC2 + Giám sát deployment từ IDE và công cụ pipeline - Thực hành bảo mật AWS cơ bản: + Bảo vệ tài khoản root và bật MFA + Tạo IAM admin user/group để tránh dùng root hàng ngày + Áp dụng chính sách mật khẩu mạnh và cân nhắc SCP để làm guardrails cho Organization - Phân tích \u0026amp; xác thực IAM: + Dùng IAM Access Analyzer để kiểm tra least-privilege + Tạo và test cross-account role cho truy cập tạm thời + Kiểm tra resource policies để phát hiện lộ thông tin public hoặc cross-account + Xem báo cáo last-accessed để loại bỏ quyền không dùng đến 10/23/2025 10/23/2025 AWS Cloud9: https://000049.awsstudygroup.com/ Elastic Beanstalk: https://000050.awsstudygroup.com/ CI/CD Pipeline: https://000051.awsstudygroup.com/ AWS Well-Architected Security Workshop: https://catalog.workshops.aws/well-architected-security 6 - Tạo microservice: + Cấu hình Eclipse IDE và phát triển Lambda function + Test cục bộ và deploy lên AWS Lambda + Triển khai ImageManager Lambda và tự động hóa bằng CodeStar CI/CD - Refactor dữ liệu \u0026amp; workflow: + Provision CloudFormation stack và tạo bảng DynamoDB mới với GSI + Xây Scan \u0026amp; Query microservice, tạo API, cập nhật IAM policy và redeploy qua CodeStar + Triển khai Calculator microservice dùng Step Functions + Lambda - Detective controls \u0026amp; incident response: + Triển khai GuardDuty và phân tích findings + Tập hợp, ưu tiên findings trong Security Hub và cấu hình remediation tự động + Dùng Detective để phân tích nguyên nhân gốc rễ của sự cố bảo mật - Bảo vệ hạ tầng: + Thiết kế VPC với phân đoạn subnet và security groups phù hợp + Triển khai Network Firewall để kiểm tra lưu lượng giữa các subnet và ra/vào Internet + Cấu hình WAF để bảo vệ ứng dụng web khỏi tấn công phổ biến + Xem xét AWS Shield Advanced cho chiến lược giảm thiểu DDoS - Bảo vệ dữ liệu \u0026amp; mã hóa: + Dùng Amazon Macie để phát hiện và phân loại dữ liệu nhạy cảm trong S3 + Áp dụng KMS key do khách hàng quản lý để mã hóa S3/EBS + Cấp SSL/TLS qua ACM cho load balancer + Quản lý và xoay vòng bí mật bằng Secrets Manager 10/24/2025 10/24/2025 Create Microservice: https://000052.awsstudygroup.com/ Refactor Data and Workflows: https://000053.awsstudygroup.com/ AWS Well-Architected Security Workshop: https://catalog.workshops.aws/well-architected-security Thành tựu tuần 7: Có kinh nghiệm thực tế vững với Amazon DynamoDB: đã tạo bảng, nạp dữ liệu, sử dụng GSI và composite keys, bật backup, và triển khai change-data-capture qua Streams và Kinesis.\nThực hiện phân tích chi phí và hiệu năng bằng cách kết hợp DynamoDB metrics với AWS Glue và Amazon Athena; thử nghiệm tagging để cải thiện phân bổ chi phí.\nTriển khai federation danh tính và quản trị IAM:\nCấu hình federation Azure AD → AWS, đồng bộ IAM roles và kiểm chứng truy cập console federated. Tạo IAM groups, users và roles với chính sách có điều kiện (theo IP và theo thời gian). Nâng cao kỹ năng tối ưu chi phí và di cư cơ sở dữ liệu bằng cách đánh giá Savings Plans và Reserved Instances; thực hành chuyển đổi schema và di cư dữ liệu với AWS SCT và DMS (bao gồm DMS Serverless và giám sát).\nTriển khai và quản lý ứng dụng trên Lightsail và dịch vụ container: chạy WordPress/Prestashop/Akaunting, quản lý snapshot và alarm, và build image Docker tùy chỉnh để deploy.\nXây dựng orchestration và bảo mật truy cập ứng dụng:\nPhát triển workflow Step Functions (Task, Choice, Wait, Retry/Catch, Parallel). Ưu tiên dùng IAM roles thay vì access keys lâu dài; gắn role cho EC2 để truy cập S3 an toàn. Tự động hóa vòng đời ứng dụng và CI/CD:\nSử dụng Cloud9, CodeStar, CodeCommit, CodeDeploy và Elastic Beanstalk để tối ưu quy trình phát triển và triển khai tự động. Củng cố posture bảo mật tổ chức:\nCứng hóa tài khoản root (MFA), xác định user/group admin, áp dụng chính sách mật khẩu, cân nhắc SCP, và dùng IAM Access Analyzer cùng báo cáo last-accessed để thu hẹp quyền. Xây dựng microservices và lớp bảo mật:\nTriển khai microservices dựa trên Lambda + DynamoDB + Step Functions, tự động hóa triển khai bằng CodeStar, và triển khai các công cụ giám sát/bảo mật (GuardDuty, Security Hub, Detective) cùng các biện pháp bảo vệ mạng/dữ liệu (VPC design, Network Firewall, WAF, Shield Advanced, Macie, KMS, ACM, Secrets Manager). "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8 Áp dụng Infrastructure as Code với AWS CloudFormation để triển khai, cập nhật và mở rộng môi trường ứng dụng. Tăng cường độ tin cậy của hệ thống thông qua kiểm thử khả năng chịu lỗi, Auto Scaling và cơ chế tự phục hồi. Xây dựng và bảo mật kiến trúc hiện đại như serverless SPA với xác thực và theo dõi hiệu năng. Khám phá các dịch vụ AI, lưu trữ và phân phối nội dung: Amazon Polly, Rekognition, Lex, S3 và CloudFront. Giám sát tài nguyên bằng CloudWatch Dashboard trên nhiều hệ điều hành và chuẩn bị cho bài đánh giá cuối tuần. Công việc đã hoàn thành trong tuần Ngày Công Việc Ngày Bắt Đầu Ngày Hoàn Thành Tài Liệu Tham Khảo 2 - Infrastructure as Code với CloudFormation + Triển khai VPC và các thành phần mạng cơ bản bằng CloudFormation + Khởi chạy ứng dụng web đa tầng trên VPC + Xem lại kiến trúc đang chạy (load balancer, Auto Scaling group, EC2) + Kiểm tra tài nguyên và outputs của stack để hiểu quá trình triển khai - Health Check nâng cao \u0026amp; Xử lý sự cố phụ thuộc + Triển khai web stack cơ bản bằng CloudFormation + Mô phỏng lỗi phụ thuộc và quan sát hành vi của ứng dụng + Cấu hình deep health check cho ALB + Triển khai cơ chế “fail open” để duy trì chức năng tối thiểu khi có lỗi dịch vụ - Nâng cấp hạ tầng bằng CloudFormation + Triển khai stack ban đầu và phân tích các thành phần + Cập nhật stack bằng cách thay đổi tham số + Mở rộng template bằng cách thêm S3 bucket + Thêm EC2 mới với cấu hình tùy chỉnh + Triển khai cùng một stack ở Region khác - Tách Monolith thành Microservices + Chuẩn bị môi trường và kết nối vào Windows instance + Phân tích kiến trúc ứng dụng monolithic + Xây dựng và triển khai microservices: Advert, Invoice, ShoppingCart, Order, User + Cung cấp nội dung tĩnh qua microservice Static + Kiểm thử tổng thể hệ thống microservices 10/27/2025 10/27/2025 AWS Well-Architected Reliability Workshop https://catalog.workshops.aws/well-architected-reliability Refactoring to Microservices https://000054.awsstudygroup.com/ 3 - Kiểm thử tính chịu lỗi với AWS FIS + Tạo IAM roles và policies cho FIS + Xây dựng template thí nghiệm nhắm vào tài nguyên cụ thể + Chạy thí nghiệm gây lỗi và theo dõi tác động + Xem log và kết quả để đánh giá hành vi hệ thống - Cấu hình Auto Scaling cho tải \u0026amp; khôi phục + Tạo launch template cho EC2 web-tier + Cấu hình target group cho ALB + Tạo Auto Scaling group + Triển khai load generator và xác nhận hành vi scale-out/scale-in - Thay thế tự động qua Health Checks + Tắt 1 EC2 thủ công để kích hoạt cơ chế tự phục hồi + Xác minh ASG tạo instance mới và health check của ALB - Thiết lập môi trường + Tạo Key Pair + Triển khai hạ tầng nền tảng qua CloudFormation + Kết nối vào Windows instance để cấu hình môi trường - Triển khai Serverless SPA + Tạo table DynamoDB + Xây dựng và triển khai Lambda microservice + Cấu hình API qua API Gateway + Tạo CI/CD pipeline với CodeStar + Triển khai SPA và xây client gọi API - Xác thực \u0026amp; Phân quyền + Tích hợp Cognito User Pools + Bảo vệ API/Lambda bằng xác thực + Tạo luồng đăng ký, đăng nhập người dùng + Kiểm thử toàn bộ auth flow - Theo dõi hiệu năng bằng X-Ray + Tích hợp AWS X-Ray để theo dõi request và tìm bottleneck 10/28/2025 10/28/2025 AWS Well-Architected Reliability Workshop https://catalog.workshops.aws/well-architected-reliability Serverless Web Application https://000055.awsstudygroup.com/ 4 - Tích hợp Amazon Polly + Trải nghiệm Polly trên console + Tạo giọng nói và speech marks bằng CLI + Sử dụng Java SDK để tổng hợp giọng nói - Nhận diện đối tượng \u0026amp; khuôn mặt với Rekognition + Chuẩn bị môi trường + Nhận diện object trong hình ảnh + Triển khai nhận diện khuôn mặt cơ bản qua ứng dụng mẫu - Xây chatbot với Amazon Lex + Triển khai ứng dụng và APIs nền tảng + Tạo và tinh chỉnh Lex bot + Implement Lambda fulfillment + Publish bot - Triển khai Website Tĩnh qua S3 \u0026amp; CloudFront + Tạo S3 bucket và upload nội dung web + Bật static website hosting + Cấu hình quyền truy cập + Tạo CloudFront distribution - Bảo vệ dữ liệu \u0026amp; replication trong S3 + Bật versioning + Thực hành di chuyển object trong bucket + Cấu hình cross-region replication 10/29/2025 10/29/2025 AI Services Integration https://000056.awsstudygroup.com/ S3 \u0026amp; CloudFront https://000057.awsstudygroup.com/ 5 - CloudWatch Dashboards để giám sát + Tạo dashboards để trực quan hóa metrics + Thêm metric widgets và Logs Insights - Giám sát EC2 Windows + Triển khai VPC networking + Khởi chạy \u0026amp; cấu hình EC2 Windows + Xây dashboard tùy chỉnh + Thêm CPU, network và performance metrics + Tạo tải thử để quan sát thay đổi - Giám sát EC2 Linux + Triển khai VPC và khởi chạy EC2 Linux với web server + Tạo dashboard giám sát + Theo dõi CPU và network performance + Tạo tải thử để kiểm tra đáp ứng hệ thống 10/30/2025 10/30/2025 AWS Well-Architected Performance Efficiency Workshop https://catalog.workshops.aws/well-architected-performance-efficiency/ 6 - NGÀY THI 10/31/2025 10/31/2025 Thành tựu đạt được trong tuần 8 Thành thạo CloudFormation: triển khai VPC, web stack đa tầng, cập nhật hạ tầng và triển khai multi-region. Nâng cao hiểu biết về tính chịu lỗi: fault injection, deep health checks, Auto Scaling, self-healing. Tách ứng dụng monolithic thành microservices (Advert, Invoice, ShoppingCart, Order, User, Static) và kiểm thử thành công toàn bộ hệ thống. Xây dựng serverless SPA hoàn chỉnh với API Gateway, Lambda, DynamoDB, CodeStar CI/CD, Cognito và X-Ray. Có kinh nghiệm thực tế với Polly, Rekognition, Lex, S3 và CloudFront. Tăng kỹ năng giám sát qua CloudWatch Dashboards với cả EC2 Windows và Linux. Hoàn thành bài kiểm tra và tổng hợp kiến thức về reliability, serverless, AI services và monitoring. "
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/1-worklog/1.9-week9/",
	"title": "Nhật ký công việc Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9: Kiến trúc các giao diện hội thoại và hệ thống hướng sự kiện sử dụng Amazon Lex và Amazon SNS. Triển khai các giải pháp dữ liệu và bộ nhớ đệm được quản lý với DynamoDB và ElastiCache, đồng thời tự động hóa việc triển khai EKS. Thực thi quản trị và khả năng mở rộng thông qua Service Quotas, kiểm soát sử dụng dựa trên IAM và EKS Blueprints. Phát triển và vận hành các khối lượng công việc serverless và container hóa, đồng thời đánh giá hiệu năng lưu trữ giữa S3 và EFS. Bảo mật hạ tầng S3 và thiết lập đường ống data lake cơ bản sử dụng Glue, Athena và QuickSight. Các nhiệm vụ đã thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Cấu hình Chatbot Amazon Lex + Cung cấp hạ tầng backend và các API cần thiết + Khởi tạo và cấu hình một instance chatbot mới trên Amazon Lex + Tinh chỉnh các intent (ý định) hội thoại và các loại slot + Triển khai Lambda hooks cho logic thực hiện (fulfillment) + Xuất bản các bí danh (alias) chatbot để sử dụng thực tế - Triển khai Mô hình Nhắn tin Publish/Subscribe với Amazon SNS + Triển khai hạ tầng cơ sở thông qua mẫu SAM + Cấu hình Amazon SNS Topic để phát tán sự kiện + Xây dựng các subscriber tách biệt: Dịch vụ Thông báo, Kế toán và Chuyến đi + Áp dụng các chính sách lọc tin nhắn để định tuyến cụ thể + Cập nhật các dịch vụ publisher và kiểm tra việc phân phối fan-out 11/03/2025 11/03/2025 Amazon Lex Chatbot: https://000058.awsstudygroup.com/ Nhắn tin với Amazon SNS: https://000059.awsstudygroup.com/ 3 - Làm việc với Amazon DynamoDB + Thực hiện các thao tác CRUD cơ bản và cung cấp bảng + Tạo và truy vấn Global Secondary Index (GSI) + Quản trị bảng thông qua AWS CloudShell + Tự động hóa quản lý bảng và truy vấn sử dụng Python SDK - Làm việc với Amazon ElastiCache cho Redis + Tạo nhóm subnet cho các lớp caching + Khởi chạy cụm Redis (Chế độ Cluster Enabled/Disabled) + Cấp quyền truy cập và kết nối qua các node client + Tích hợp AWS SDK cho các thao tác Redis + Triển khai các mẫu nâng cao: Strings, Hashes, Pub/Sub và Streams - Xây dựng Pipeline CI/CD cho Cụm EKS + Thiết lập môi trường Cloud9 và các công cụ Kubernetes + Cấu hình IAM role cho xác thực EKS + Cung cấp cụm EKS và kiểm tra triển khai ứng dụng mẫu + Thiết lập CodePipeline và CodeBuild với các quyền IAM + Tự động hóa triển khai manifest từ kho mã nguồn + Xác minh việc thực thi pipeline thông qua các trigger code commit 11/04/2025 11/04/2025 Amazon DynamoDB Workshop: https://000060.awsstudygroup.com/ Amazon ElastiCache Workshop: https://000061.awsstudygroup.com/ EKS CI/CD Workshop: https://000062.awsstudygroup.com/ 4 - Quản lý Service Quotas + Kiểm tra mức sử dụng hiện tại so với giới hạn + Yêu cầu tăng hạn mức thông qua console Service Quotas - Thực hiện Quản lý Chi phí và Sử dụng Tài nguyên với IAM + Cấu trúc nhóm/người dùng IAM cho các ranh giới quyền hạn + Thực thi chính sách hạn chế tài nguyên theo Vùng (Region) AWS + Giới hạn các họ EC2 instance được phép sử dụng + Áp dụng hạn chế về kích thước EC2 instance + Kiểm soát chi phí bằng cách giới hạn các loại EBS volume khả dụng - Triển khai và Quản lý Cụm EKS sử dụng EKS Blueprints + Khởi động hạ tầng: Thiết lập VPC và EC2 + Cấu hình IAM role cho thiết lập EKS Blueprints + Khởi tạo dự án EKS Blueprints và CDK + Xây dựng pipeline triển khai để quản lý cụm + Quản lý truy cập đa nhóm thông qua Cơ sở hạ tầng dưới dạng mã (IaC) + Tích hợp các add-on như Cluster Autoscaler + Triển khai khối lượng công việc sử dụng GitOps (ArgoCD) 11/05/2025 11/05/2025 Service Quotas Workshop: https://000063.awsstudygroup.com/ Quản lý Tài nguyên IAM: https://000064.awsstudygroup.com/ EKS Blueprints Workshop: https://000065.awsstudygroup.com/ 5 - Xây dựng Ứng dụng Web Serverless sử dụng Lambda và API Gateway + Thiết lập Cloud9 và CodeCommit để quản lý phiên bản + Host frontend thông qua AWS Amplify Console + Triển khai backend serverless (Lambda + API Gateway) + Khởi tạo dữ liệu trạng thái cho DynamoDB + Tích hợp logic đặt chuyến đi (ride-booking) + Phát triển quy trình xử lý ảnh sử dụng Lambda - Chuyển đổi Ứng dụng Monolithic sang Microservices sử dụng Docker và AWS Fargate + Cung cấp môi trường thông qua CloudFormation + Container hóa ứng dụng cũ (legacy) với Docker + Triển khai container lên AWS Fargate serverless + Cấu hình Application Load Balancer và ECS Services + Quản lý các bản sửa đổi (revision) task definition và cập nhật + Tái cấu trúc và triển khai microservices song song với monolith - Đánh giá Hiệu năng Lưu trữ trên AWS + Triển khai hạ tầng kiểm thử qua CloudFormation + Kiểm chuẩn thông lượng S3 và hiệu quả đồng bộ hóa + Phân tích hiệu năng cho các tệp nhỏ và thao tác sao chép + Tinh chỉnh EFS IOPS và đánh giá tác động của kích thước I/O + Đánh giá ảnh hưởng của đa luồng (multi-threading) lên hiệu năng EFS 11/06/2025 11/06/2025 Ứng dụng Web Serverless: https://000066.awsstudygroup.com/ Microservices với Fargate: https://000067.awsstudygroup.com/ Đánh giá Hiệu năng Lưu trữ: https://000068.awsstudygroup.com/ 6 - Triển khai Các phương pháp Bảo mật Tốt nhất cho S3 + Bảo mật truy cập mạng thông qua CloudFormation + Cấu hình khóa truy cập an toàn cho EC2 + Bắt buộc sử dụng giao thức HTTPS và mã hóa SSE-S3 + Bật \u0026ldquo;Block Public Access\u0026rdquo; và vô hiệu hóa ACLs + Hạn chế truy cập sử dụng S3 VPC Endpoints + Kiểm toán cấu hình với AWS Config + Xác minh quyền truy cập với Access Analyzer - Xây dựng Data Lake với Dữ liệu của Bạn + Tập kết dữ liệu thô trong Cloud9 và S3 + Lập hồ sơ và làm sạch dữ liệu sử dụng AWS DataBrew + Lập danh mục và thu thập dữ liệu với AWS Glue + Chuyển đổi bộ dữ liệu sang định dạng Parquet + Thực thi các truy vấn phân tích thông qua Amazon Athena + Trực quan hóa thông tin chi tiết với dashboard Amazon QuickSight 11/07/2025 11/07/2025 Các phương pháp Bảo mật Tốt nhất cho S3: https://000069.awsstudygroup.com/ Data Lake Workshop: https://000070.awsstudygroup.com/ Thành tựu Tuần 9: Thiết kế các quy trình hội thoại và hệ thống nhắn tin bằng cách triển khai chatbot Amazon Lex với Lambda hooks và thiết lập kiến trúc SNS Pub/Sub tách biệt.\nLàm chủ các dịch vụ dữ liệu và bộ nhớ đệm được quản lý:\nThực hiện các thao tác cốt lõi trên DynamoDB, bao gồm quản lý GSI và tự động hóa dựa trên SDK. Triển khai các cụm ElastiCache cho Redis, áp dụng các mẫu caching nâng cao như Pub/Sub và Streams. Tự động hóa vòng đời Kubernetes bằng việc cung cấp các cụm EKS, định nghĩa IAM roles, và xây dựng các pipeline CI/CD với CodePipeline để hợp lý hóa việc triển khai ứng dụng.\nThực thi quản trị đám mây và tối ưu hóa chi phí:\nKiểm toán và quản lý AWS Service Quotas cho khả năng mở rộng. Áp dụng các chính sách IAM chi tiết để hạn chế sử dụng tài nguyên theo Vùng, Loại Instance và đặc tính Volume. Tận dụng EKS Blueprints và IaC để khởi động hạ tầng mạng, quản lý truy cập đa nhóm, và triển khai các add-on (Autoscaler) cùng khối lượng công việc thông qua ArgoCD.\nKiến trúc các giải pháp ứng dụng hiện đại:\nXây dựng ứng dụng đặt xe serverless full-stack sử dụng Amplify, API Gateway và Lambda. Tái cấu trúc ứng dụng monolithic thành microservices, đóng gói bằng Docker và triển khai trên AWS Fargate. Kiểm chuẩn hiệu năng lưu trữ bằng cách phân tích thông lượng S3 và tốc độ truyền tải, song song với việc tinh chỉnh cấu hình IOPS và luồng của EFS.\nCủng cố tư thế bảo mật S3:\nBắt buộc mã hóa và HTTPS, chặn truy cập công khai qua ACLs, và hạn chế lưu lượng qua VPC Endpoints. Sử dụng AWS Config và Access Analyzer để kiểm toán và khắc phục các rủi ro bảo mật tiềm ẩn. Thiết lập nền tảng Data Lake: tập kết dữ liệu vào S3, chuyển đổi thông qua Glue/DataBrew, và kích hoạt phân tích với truy vấn Athena cùng trực quan hóa QuickSight.\n"
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nicolaihong.github.io/InternReport_FCJ/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]