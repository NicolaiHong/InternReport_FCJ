[
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen đội ngũ và nắm vững các khái niệm cơ bản về AWS\nTuần 2: Định hướng dự án game gõ chữ, xây dựng microservice trên AWS và nền tảng vận hành\nTuần 3: Thực hành AWS, tài liệu UI/UX và tích hợp NoSQL cho dự án 1\nTuần 4: RDS, Auto Scaling, CloudWatch, Route 53, CLI, CI/CD, Docker, Serverless, và Security Hub\nTuần 5: Từ mạng đến triển khai: VPC Peering, Transit Gateway, WordPress, tối ưu chi phí Lambda, CI/CD, Storage Gateway, FSx \u0026amp; WAF\nTuần 6: Quản lý truy cập IAM, hệ thống giám sát (Grafana \u0026amp; CloudWatch), Systems Manager, tối ưu kích thước EC2, mã hóa S3, Cost Explorer, data lake và tự động hóa với CloudFormation\nTuần 7: Đào sâu DynamoDB, liên kết IAM federation \u0026amp; tối ưu chi phí, Lightsail \u0026amp; containers, Step Functions, Cloud9, Elastic Beanstalk, pipeline CI/CD và nền tảng bảo mật AWS\nTuần 8: IaC với CloudFormation, độ bền \u0026amp; auto scaling, tách thành microservices, SPA serverless với Cognito \u0026amp; X-Ray, dịch vụ AI (Polly, Rekognition, Lex), S3 \u0026amp; CloudFront, và dashboard CloudWatch\nTuần 9: Chatbot Lex \u0026amp; mô hình pub/sub SNS, lab DynamoDB \u0026amp; ElastiCache, EKS CI/CD \u0026amp; Blueprints, microservices serverless \u0026amp; Fargate, đánh giá hiệu năng lưu trữ, best practices bảo mật S3, và data lake với Glue, Athena \u0026amp; QuickSight\nTuần 10: Triển khai ROSA, nền tảng phân tích với Kinesis, Glue, EMR, Athena, QuickSight \u0026amp; Redshift, dashboard nghiệp vụ, VPC Flow Logs, ủy quyền billing, CDK, event-driven (SNS/SQS) và full serverless stack với Cognito, CloudFront, SQS/SNS cùng CI/CD\nTuần 11: Sự kiện cộng đồng AWS, dịch vụ text serverless với DynamoDB, caching \u0026amp; validation, tích hợp Amazon Bedrock Agent, giám sát bằng CloudWatch \u0026amp; X-Ray, và API GraphQL với AppSync \u0026amp; DynamoDB\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Hồng Lê Đăng Khoa\nSố điện thoại: 0773018623\nEmail: hongkhoa348@gmail.com\nTrường: Đại học FPT Campus Thành phố Hồ Chí Minh\nNgành: Kỹ thuật phần mền\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ 09/2025 đến 02/2026\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Nhật ký công việc Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 1: Giới thiệu bản thân và kết nối với nhóm First Cloud Journey. Học cách viết worklog và cách tổ chức/workshop. Hiểu các dịch vụ cơ bản của AWS và biết cách sử dụng AWS Management Console và AWS CLI. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Làm quen và giới thiệu với các thành viên FCJ - Đọc và ghi chú các quy định và nội quy thực tập 09/08/2025 09/08/2025 Policies: https://policies.fcjuni.com/ 3 - Tìm hiểu về AWS và các nhóm dịch vụ chính phục vụ dự án sau này + Compute + Storage + Networking + Database + Khác - Xem hướng dẫn/video về cách tổ chức workshop và viết tài liệu 09/09/2025 09/09/2025 About AWS: https://cloudjourney.awsstudygroup.com/ About workshop: https://van-hoang-kha.github.io/vi/ 4 - Áp dụng hướng dẫn viết workshop để soạn worklog này - Tạo tài khoản AWS Free Tier - Tìm hiểu AWS Management Console và cài đặt/cấu hình AWS CLI - Thực hành: + Tạo tài khoản AWS + Cài \u0026amp; cấu hình AWS CLI + Sử dụng cơ bản AWS CLI 09/10/2025 09/10/2025 My workshop git: https://github.com/isntbim/internship_report AWS Console: https://aws.amazon.com/ 5 - Học các khái niệm cơ bản về EC2: + Các loại instance + AMI + EBS + Lưu trữ - Thử khởi chạy instance EC2 - Các phương thức kết nối SSH tới EC2 - Tìm hiểu về Elastic IP 09/11/2025 09/11/2025 EC2 console: https://ap-southeast-1.console.aws.amazon.com/ec2/ Amazon EC2 Basics: https://www.coursera.org/learn/aws-amazon-ec2-basics/ 6 - Thực hành thêm: + Khởi chạy một EC2 instance + Kết nối qua SSH + Gắn thêm ổ EBS 09/12/2025 09/12/2025 EC2 console: https://ap-southeast-1.console.aws.amazon.com/ec2/ Thành tựu Tuần 1 (đang tiếp tục): Nắm được khái niệm về AWS và làm quen với các nhóm dịch vụ chính:\nCompute Storage Networking Database Các dịch vụ khác Đã tạo và cấu hình thành công tài khoản AWS Free Tier.\nLàm quen với định dạng workshop và cách viết worklog.\nThành thạo thao tác cơ bản trên AWS Management Console: tìm, truy cập và sử dụng dịch vụ qua giao diện web.\nCài đặt và cấu hình AWS CLI, bao gồm:\nAccess Key Secret Key Vùng mặc định (Default Region) Các thiết lập liên quan Hiểu các khái niệm cơ bản về EC2:\nCác loại instance — cân bằng giữa chi phí và hiệu năng. AMI — ảnh máy/ảnh hệ điều hành dùng để khởi tạo instance. EBS — ổ lưu trữ block bền cho instance. Các lựa chọn lưu trữ — chọn loại lưu trữ phù hợp theo nhu cầu. Elastic IP — địa chỉ IP tĩnh gán cho instance trong môi trường đám mây. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Nhật ký công việc Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 2: Xác định và xác phạm vi cho dự án trò chơi gõ chữ đầu tiên (tính năng cốt lõi, ranh giới microservice, hướng phát triển matchmaking). Xây dựng nền tảng đội: repository chung, backlog khởi tạo, sơ đồ ER, lựa chọn tech stack, phân công ownership. Chuẩn hóa công thức tính WPM và accuracy. Prototype dịch vụ FastAPI: sinh văn bản, ghép câu, chat; kiểm chứng con đường tích hợp với Bedrock. Thiết lập AWS Budgets kèm cảnh báo. Nâng cao khả năng thực hành: Lambda (function URL), VPC (subnet, gateway, peering vs transit), VPC Flow Logs, khái niệm cân bằng tải. Provision Amazon RDS; thiết kế schema và seed dataset cho truy xuất văn bản. Refactor dịch vụ text sang truy xuất dựa trên DB; benchmark so sánh với phương pháp API trước đó. Giới thiệu các thực hành vận hành sớm: phân công vai trò, benchmark, giám sát để đảm bảo khả năng scale. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tổ chức buổi brainstorming nhóm để xác định và ưu tiên ý tưởng cho dự án đầu tiên + Chuyển ghi chú từ canvas dự án vào backlog khởi tạo trên bảng quản lý dự án + Nghiên cứu và ghi chép các thuật toán cụ thể để tính WPM và accuracy nhằm đảm bảo tính nhất quán + Tạo repository chung và thiết lập cấu trúc dự án cơ bản cho các ngôn ngữ và microservice đã chọn + Hoàn thiện các phác thảo sơ đồ ER và bắt đầu soạn sơ bộ các schema cơ sở dữ liệu + Phân công chính thức người phụ trách lead cho từng microservice để tinh giản quá trình phát triển 09/15/2025 09/15/2025 3 - Thiết lập AWS Budgets: + Xem lại các loại budget (Cost, Usage, RI, v.v.) + Định nghĩa ngưỡng chi phí hàng tháng + Cấu hình budget trong AWS Console + Thiết lập cảnh báo email/SNS - Tạo web app nhỏ dùng AWS Lambda: + Tìm hiểu Lambda và cơ bản về function URL + Viết hàm \u0026ldquo;Hello World\u0026rdquo; đơn giản + Cấu hình hàm và IAM role tương ứng + Kích hoạt và kiểm thử endpoint function URL - Thử nghiệm FastAPI cho microservice: + Thực hành theo tutorial FastAPI chính thức + Thiết lập môi trường phát triển local + Xây dựng API proof-of-concept + Triển khai và thử nghiệm các endpoint qua Swagger UI 09/16/2025 09/16/2025 AWS Lambda: https://ap-southeast-1.console.aws.amazon.com/lambda AWS Budgets: https://us-east-1.console.aws.amazon.com/costmanagement/ FastAPI: https://www.coursera.org/learn/packt-mastering-rest-apis-with-fastapi-1xeea/ 4 - Tìm hiểu các kiến thức cơ bản về mạng và bảo mật trên AWS + Ôn lại khái niệm Amazon VPC như một vùng mạng cô lập trong AWS + Hiểu vai trò của subnet và phân biệt subnet public vs private để cấu trúc mạng + Nắm mục đích của Internet Gateway (IGW) để cung cấp truy cập internet cho subnet public và NAT Gateway để cho subnet private truy cập internet một cách an toàn + Khám phá VPC Flow Logs như công cụ giám sát và gỡ lỗi lưu lượng mạng trong VPC + So sánh các phương án kết nối on-premise tới AWS: Site-to-Site VPN (mã hóa qua internet) và Direct Connect (kết nối riêng, private) + Hiểu các trường hợp sử dụng VPC Peering (kết nối trực tiếp giữa hai VPC) so với Transit Gateway + Nắm khái niệm Elastic Load Balancing (ELB) để phân phối traffic giữa nhiều server nhằm tăng tính sẵn sàng 09/17/2025 09/17/2025 Module 02-(01 to 03): https://www.youtube.com/watch?v=O9Ac_vGHquM https://www.youtube.com/watch?v=BPuD1l2hEQ4 https://www.youtube.com/watch?v=CXU8D3kyxIc 5 - Khám phá Amazon Bedrock playground: + Xem các foundation model có sẵn (ví dụ: Claude, Titan) + Chọn model ứng viên để sinh văn bản + Thực nghiệm với các prompt và tham số khác nhau + Sinh và phân tích mẫu phản hồi - Prototype microservice được chỉ định: + Thiết kế logic dịch vụ và tích hợp nhiều API để sinh văn bản + Triển khai các hàm tạo câu ngẫu nhiên và chức năng chat + Đánh giá những hạn chế ban đầu của bản dựng và liệt kê bước tiếp theo để cải tiến + Xác thực phương án kỹ thuật đã chọn 09/18/2025 09/18/2025 Amazon Bedrock:https://ap-southeast-1.console.aws.amazon.com/bedrock 6 - Khởi tạo và cấu hình Amazon RDS: + Xem xét và chọn engine DB phù hợp với nhu cầu dự án + Cấu hình các thiết lập chính cho instance, bao gồm credentials, VPC và security group rules + Khởi tạo DB, theo dõi quá trình tạo và lưu trữ an toàn endpoint kết nối - Prototype TextService dựa trên DB: + Thiết kế schema đơn giản với bảng lưu từ và câu để chứa nội dung văn bản + Viết script một lần để populate dữ liệu khởi tạo vào RDS + Refactor TextService để truy vấn dữ liệu từ DB thay vì gọi API bên ngoài và thực hiện benchmark cải thiện hiệu năng + Chạy benchmark so sánh thời gian phản hồi giữa phương pháp trước (API) và phương pháp mới (DB) 09/19/2025 09/19/2025 Aurora and RDS: https://ap-southeast-1.console.aws.amazon.com/rds Thành tựu Tuần 2: Đã xác định phạm vi cho trò chơi gõ chữ đầu tiên: Tính năng cốt lõi Ranh giới microservice Backlog đã được seed Phân công ownership. Công thức chuẩn cho WPM và accuracy đã được nghiên cứu và ghi chép. Repository chung đã được khởi tạo với cấu trúc đa ngôn ngữ cơ bản. Sơ đồ ER được hoàn thiện và sơ bộ schema quan hệ đã được soạn thảo. Prototype FastAPI đã được giao (sinh văn bản, ghép câu, chat) và kiểm chứng qua Swagger UI. AWS Budgets được cấu hình với ngưỡng hàng tháng và cảnh báo. Nắm vững nền tảng AWS cốt lõi: Lambda (function URL) VPC (subnet, IGW, NAT, Flow Logs) Peering vs Transit Gateway Khái niệm cân bằng tải Đã khảo sát Amazon Bedrock và xác nhận model ứng viên cùng chiến lược prompt. Instance RDS được khởi tạo, schema tạo xong và dataset seed đã được nạp. TextService được refactor sang truy xuất từ DB và ghi nhận cải thiện hiệu năng ban đầu qua benchmark. Đã giới thiệu các thực hành vận hành sớm: phân công vai trò, tập trung benchmark và cân nhắc khả năng mở rộng. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của Tuần 3: Hoàn thành các lab AWS quan trọng, bao gồm Site-to-Site VPN và các thao tác cơ bản với EC2. Học và hoàn thành đầy đủ bốn module của khóa AWS Cloud Technical Essentials. Nâng cao kỹ năng sử dụng AWS Console và AWS CLI (quản lý credential, key pairs, khám phá region và service). Phối hợp với đội product/design để phân tích và ghi chú UI/UX của TypeRush từ bản thiết kế Figma. Đánh giá các phương án lưu trữ và đưa ra quyết định sử dụng NoSQL cho TextService. Thử nghiệm tích hợp MongoDB (tạo môi trường, seeding, refactor service, kiểm thử). Xây dựng thói quen trao đổi và cộng tác hiệu quả với team First Cloud Journey. Các công việc đã thực hiện trong tuần: Day Task Start Date Completion Date Reference Material 2 - Lab 03: AWS Site-to-Site VPN: + Xây dựng đầy đủ môi trường Site-to-Site VPN gồm VPC mới, EC2 đóng vai Customer Gateway, Virtual Private Gateway và VPN Connection. + Cấu hình và kiểm tra kết nối đường hầm VPN. - Lab 04: Amazon EC2 Fundamentals: + Khởi tạo và kết nối EC2 Windows Server và Amazon Linux. + Triển khai ứng dụng CRUD \u0026ldquo;AWS User Management\u0026rdquo; trên cả Windows và Linux. + Khám phá các tính năng EC2: thay đổi type, quản lý snapshot EBS, tạo custom AMI. 09/22/2025 09/22/2025 VPN Lab (Lab 03): https://000003.awsstudygroup.com/ EC2 Lab (Lab 04): https://000004.awsstudygroup.com/ 3 - Bắt đầu khóa AWS Cloud Technical Essentials và hoàn thành 2 module đầu: + Module 1: Cloud Foundations \u0026amp; IAM - Định nghĩa cloud computing và giá trị của nó. - So sánh workload on-premise và workload trên cloud. - Tạo tài khoản AWS và tìm hiểu các cách tương tác (Console/CLI/SDK). - Tìm hiểu Global Infrastructure (Region, AZ). - Học và áp dụng best practices của IAM. + Module 2: Compute \u0026amp; Networking - Tìm hiểu kiến trúc EC2. - Phân biệt container và virtual machine. - Khám phá serverless và các trường hợp sử dụng. - Tìm hiểu VPC và tạo custom VPC. 09/23/2025 09/23/2025 AWS Cloud Technical Essentials: https://www.coursera.org/learn/aws-cloud-technical-essentials 4 - Phối hợp với team design để tài liệu hóa UI/UX TypeRush: + Tham gia buổi review cross-functional để xem xét toàn bộ flow Figma mới. + Phân tích các màn hình chính (login, game, score, settings) để hiểu bố cục, visual hierarchy và user interaction. + Ghi lại danh sách câu hỏi kỹ thuật và các điểm cần xác thực với design. + Bắt đầu chuyển thiết kế thành yêu cầu component và user stories phục vụ cho sprint sau. - Thảo luận hướng lưu trữ TextService với team lead: + So sánh mô hình lưu trữ SQL và NoSQL dựa trên cấu trúc dữ liệu và cách truy cập. + Trình bày ưu/nhược điểm và case sử dụng. + Chốt sử dụng NoSQL vì linh hoạt và dễ mở rộng. 09/24/2025 09/24/2025 5 - Tích hợp và thử nghiệm MongoDB cho prototype TextService: + Dựng môi trường MongoDB bằng Docker. + Điều chỉnh script seeding để insert tài liệu (words/sentences) vào collection. + Refactor TextService để đọc/ghi qua MongoDB. + Kiểm thử đầy đủ để xác nhận kết nối và luồng dữ liệu hoạt động đúng. 09/25/2025 09/25/2025 6 - Hoàn thành 2 module cuối của AWS Cloud Technical Essentials: + Module 3: Storage \u0026amp; Databases - Phân biệt file storage, block storage và object storage. - Tìm hiểu Amazon S3, tạo S3 bucket. - Tìm hiểu EBS và các dịch vụ database của AWS. - Tạo DynamoDB table. + Module 4: Monitoring \u0026amp; High Availability - Tìm hiểu CloudWatch và các lợi ích khi monitoring. - Học cách tối ưu hiệu suất và chi phí. - Tìm hiểu cơ chế ELB phân phối lưu lượng. - Phân biệt scaling up và scaling out, triển khai mô hình high availability. 09/26/2025 09/26/2025 AWS Cloud Technical Essentials: https://www.coursera.org/learn/aws-cloud-technical-essentials Thành tựu Tuần 3: Hoàn tất các AWS Labs:\nXây dựng Site-to-Site VPN hoàn chỉnh (VPC, EC2 gateway, virtual private gateway, cấu hình tunnel). Hoàn thiện EC2 fundamentals: chạy Windows/Linux, deploy CRUD app, quản lý snapshot, tạo custom AMI. Hoàn thành toàn bộ 4 module của AWS Cloud Technical Essentials\n(Cloud Foundations/IAM, Compute \u0026amp; Networking, Storage \u0026amp; Databases, Monitoring \u0026amp; High Availability).\nNâng cao kỹ năng AWS Console \u0026amp; CLI:\nQuản lý tài khoản, IAM credentials. Điều hướng service/region thành thạo hơn. Thao tác với key pair và các lệnh CLI để kiểm tra tài nguyên. Tài liệu hóa UI/UX TypeRush:\nReview toàn bộ flow trên Figma. Ghi nhận trạng thái component và câu hỏi khả thi kỹ thuật. Soạn các user story và yêu cầu ban đầu. Chiến lược lưu trữ TextService:\nĐánh giá SQL vs NoSQL. Quyết định sử dụng NoSQL để tăng tính linh hoạt và khả năng mở rộng. Prototype MongoDB:\nDựng môi trường Docker. Viết lại script seeding. Refactor service sang MongoDB. Kiểm thử toàn bộ luồng đọc/ghi dữ liệu. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 4: Nắm vững cấu hình Amazon RDS, bao gồm thiết lập VPC, security group và quản lý backup. Học triển khai ứng dụng web có khả năng mở rộng bằng Auto Scaling Group và Application Load Balancer. Củng cố kỹ năng giám sát với CloudWatch: metrics, logs, alarms và dashboard tùy chỉnh. Tìm hiểu mô hình DNS lai sử dụng Route 53 Resolver trong môi trường doanh nghiệp. Thành thạo AWS CLI để quản lý tài nguyên S3, EC2, VPC và IAM. Xây dựng pipeline CI/CD hoàn chỉnh với CodeCommit, CodeBuild, CodeDeploy và CodePipeline. Thiết lập chiến lược backup tự động bằng AWS Backup và lifecycle policy. Triển khai ứng dụng container với Docker và container registry trên AWS. Tìm hiểu quy trình di chuyển máy ảo (VM) gồm import và export giữa các môi trường. Xây dựng ứng dụng serverless bằng AWS Lambda và API Gateway. Hiểu hệ thống giám sát bảo mật tập trung bằng AWS Security Hub. Các nhiệm vụ đã hoàn thành trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu tham khảo 2 - Cấu hình và quản lý Amazon RDS: + Thiết lập VPC, security group và DB subnet group + Tạo EC2 và RDS instance + Deploy ứng dụng mẫu kết nối RDS + Thực hiện backup và restore + Dọn dẹp tài nguyên - Triển khai ứng dụng có khả năng mở rộng: + Cấu hình VPC, subnet và security group + Tạo Launch Template + Tạo Target Group và ALB + Tạo Auto Scaling Group với chính sách manual / scheduled / dynamic + Dọn tài nguyên - Giám sát với CloudWatch: + Phân tích metrics bằng search và math expression + Query logs bằng Logs Insights + Tạo Metric Filter + Tạo Alarm + Xây dashboard + Xóa alarms và dashboards 29/09/2025 29/09/2025 RDS, Auto Scaling, CloudWatch Labs 3 - Triển khai DNS lai với Route 53 Resolver: + Deploy hạ tầng bằng CloudFormation + Tạo Microsoft AD mô phỏng DNS on-prem + Tạo outbound \u0026amp; inbound endpoint + Cấu hình rule chuyển tiếp DNS + Kiểm tra phân giải 2 chiều và dọn tài nguyên - Quản lý AWS bằng CLI: + Cài đặt và cấu hình AWS CLI + Quản lý S3, SNS, IAM bằng CLI + Thao tác bucket và object + Tạo và quản lý VPC bằng CLI + Tạo và xoá EC2 bằng CLI + Dọn tài nguyên 30/09/2025 30/09/2025 Route 53 Resolver, AWS CLI Labs 4 - Xây dựng pipeline CI/CD tự động: + Tạo repo CodeCommit + Cấu hình CodeBuild để build và package app + Tạo CodeDeploy để tự động deploy + Dùng CodePipeline để điều phối toàn bộ quy trình + Test bằng cách push code + Dọn tài nguyên - Tự động hóa backup EC2 bằng AWS Backup: + Deploy hạ tầng bằng CloudFormation + Tạo backup plan với lifecycle policy + Cấu hình thông báo backup + Test backup \u0026amp; restore + Xoá stack và backup 01/10/2025 01/10/2025 CodePipeline, AWS Backup Labs 5 - Triển khai ứng dụng Docker trên AWS: + Tạo VPC, security group, IAM role + Tạo RDS instance + Deploy ứng dụng bằng Docker image + Triển khai lại bằng Docker Compose + Push image lên ECR / Docker Hub + Xóa tài nguyên - Di chuyển máy ảo (VM Import/Export): + Export VM từ on-prem + Upload image lên S3 + Import thành AMI + Tạo EC2 từ AMI + Export EC2 trở lại S3 + Xóa toàn bộ 02/10/2025 02/10/2025 Docker on AWS, VM Import/Export Labs 6 - Triển khai ứng dụng serverless: + Chuẩn bị package Lambda + Tạo IAM role cho Lambda + Deploy Lambda function + Tạo HTTP API và tích hợp Lambda + Deploy và test endpoint + Xóa API, Lambda, IAM role - Giám sát bảo mật tập trung với Security Hub: + Enable Security Hub + Xem dashboard và findings + Phân tích phát hiện từ GuardDuty, Inspector, Macie + Xem biểu đồ rủi ro 03/10/2025 03/10/2025 Lambda \u0026amp; Security Hub Labs Thành tựu Tuần 4: Cấu hình thành công Amazon RDS cùng toàn bộ networking và backup. Xây dựng hạ tầng Auto Scaling + ALB cho ứng dụng mở rộng. Hoàn thiện giám sát CloudWatch với metrics, logs, alarms, dashboards. Cấu hình DNS lai với Route 53 Resolver + Microsoft AD. Thành thạo AWS CLI cho nhiều dịch vụ khác nhau. Xây dựng pipeline CI/CD tự động đầy đủ. Thiết lập backup tự động theo lifecycle với AWS Backup. Deploy ứng dụng Docker và publish image lên ECR. Hoàn tất quy trình di chuyển VM import/export. Xây dựng ứng dụng serverless với Lambda + API Gateway. Giám sát bảo mật tập trung bằng Security Hub. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 5: Triển khai các kỹ thuật networking nâng cao với VPC Peering và Transit Gateway để kết nối nhiều VPC. Deploy ứng dụng full-stack sử dụng EC2, RDS, Auto Scaling và tích hợp CloudFront. Xây dựng giải pháp tối ưu chi phí bằng serverless với AWS Lambda để tự động quản lý EC2. Thiết lập pipeline CI/CD bằng bộ công cụ AWS Developer Tools cho quá trình deploy tự động. Cấu hình hybrid cloud storage bằng AWS Storage Gateway để kết nối môi trường on-premises. Quản lý hệ thống file doanh nghiệp bằng Amazon FSx và tăng cường bảo mật web bằng AWS WAF. Tổ chức tài nguyên AWS hiệu quả với Tags và Resource Groups. Nâng cao kỹ năng thao tác bằng cả AWS Management Console và AWS CLI. Nhiệm vụ đã thực hiện trong tuần: Ngày Công việc Bắt đầu Hoàn thành Tài liệu tham khảo 2 - Thiết lập VPC Peering giữa hai VPC:\n+ Khởi tạo môi trường bằng CloudFormation\n+ Tạo Security Group cho EC2\n+ Khởi tạo EC2 ở từng VPC để kiểm tra kết nối\n+ Cập nhật Network ACLs\n+ Tạo \u0026amp; chấp nhận kết nối Peering\n+ Cấu hình Route Tables để định tuyến\n+ Bật Cross-Peer DNS để resolve tên miền\n- Triển khai kiến trúc mạng mở rộng với Transit Gateway:\n+ Tạo Key Pair\n+ Khởi tạo môi trường bằng CloudFormation\n+ Tạo Transit Gateway làm trung tâm kết nối\n+ Gắn các VPC vào Transit Gateway\n+ Cấu hình Transit Gateway Route Tables\n+ Cập nhật Route Tables của VPC 10/06/2025 10/06/2025 VPC Peering: https://000019.awsstudygroup.com/ Transit Gateway: https://000020.awsstudygroup.com/ 3 - Triển khai WordPress trên AWS:\n+ Chuẩn bị VPC/Subnet\n+ Tạo Security Group cho EC2 và RDS\n+ Tạo EC2 host WordPress\n+ Tạo RDS cho database\n+ Cài đặt và cấu hình WordPress\n+ Thiết lập Auto Scaling\n+ Thực hiện backup/restore database\n+ Tích hợp CloudFront để tăng tốc hiệu năng\n- Tối ưu chi phí EC2 bằng Lambda:\n+ Gắn tags cho EC2 để quản lý chi phí\n+ Tạo IAM Role cho Lambda\n+ Viết Lambda tự động tắt/bật EC2\n+ Kiểm thử hoạt động của Lambda 10/07/2025 10/07/2025 WordPress: https://000021.awsstudygroup.com/ Lambda Optimization: https://000022.awsstudygroup.com/ 4 - Tự động hoá triển khai ứng dụng với CI/CD Pipeline:\n+ Chuẩn bị tài nguyên cần thiết\n+ Cài đặt CodeDeploy Agent lên EC2\n+ Tạo repo CodeCommit lưu mã nguồn\n+ Cấu hình CodeBuild để build ứng dụng\n+ Thiết lập CodeDeploy để deploy tự động\n+ Xây dựng CodePipeline orchestrate toàn bộ pipeline\n+ Xử lý lỗi trong quá trình chạy pipeline\n- Sử dụng Storage Gateway cho hybrid cloud:\n+ Tạo S3 Bucket\n+ Tạo EC2 host Storage Gateway\n+ Khởi tạo Storage Gateway\n+ Tạo File Shares\n+ Mount File Shares trên máy on-premises 10/08/2025 10/08/2025 CI/CD: https://000023.awsstudygroup.com/ Storage Gateway: https://000024.awsstudygroup.com/ 5 - Quản lý Amazon FSx for Windows File Server:\n+ Tạo môi trường\n+ Tạo file system SSD và HDD Multi-AZ\n+ Tạo file shares\n+ Kiểm thử hiệu năng\n+ Bật Data Deduplication \u0026amp; Shadow Copies\n+ Quản lý sessions, open files, quotas\n+ Bật Continuous Access share\n+ Scale throughput và storage\n+ Xoá môi trường khi hoàn tất\n+ Tham khảo AWS CLI để quản lý FSx\n- Triển khai AWS WAF:\n+ Tạo S3 bucket và deploy web mẫu\n+ Sử dụng Managed Rules\n+ Tạo Custom Rules nâng cao\n+ Kiểm thử rule\n+ Bật logging\n+ Cleanup tài nguyên 10/09/2025 10/09/2025 Amazon FSx: https://000025.awsstudygroup.com/ AWS WAF: https://000026.awsstudygroup.com/ 6 - Quản lý tài nguyên bằng Tags \u0026amp; Resource Groups:\n+ Hiểu và sử dụng tags trên Console\n+ Tạo EC2 với tags\n+ Thêm/xoá tags trên resource\n+ Lọc tài nguyên theo tags\n+ Sử dụng tags với AWS CLI\n+ Gắn tags cho EC2 qua CLI\n+ Gắn tags khi tạo mới tài nguyên bằng CLI\n+ Liệt kê tài nguyên có tag bằng CLI\n+ Tạo Resource Group dựa trên tags\n+ Quản lý tài nguyên trong Resource Group 10/10/2025 10/10/2025 Tags \u0026amp; Resource Groups: https://000027.awsstudygroup.com/ Thành tựu Tuần 5: Hoàn thiện networking nâng cao trên AWS:\nVPC Peering giúp kết nối trực tiếp giữa các VPC Transit Gateway làm trung tâm kết nối toàn hệ thống Cấu hình routing và DNS giữa nhiều VPC Deploy và tối ưu ứng dụng cloud:\nWordPress tích hợp RDS Auto Scaling + CloudFront tăng hiệu năng và tính sẵn sàng Lambda tối ưu chi phí EC2 tự động Xây dựng quy trình DevOps hoàn chỉnh:\nPipeline CI/CD đầy đủ với CodeCommit – CodeBuild – CodeDeploy – CodePipeline Tự động hoá triển khai Hybrid storage bằng Storage Gateway Quản lý hệ thống file và bảo mật ở cấp doanh nghiệp:\nFSx Multi-AZ, quản lý quotas, deduplication AWS WAF với quản lý rule nâng cao Áp dụng chiến lược quản trị tài nguyên hiệu quả:\nTối ưu chi phí \u0026amp; quản lý bằng Tags Quản lý tài nguyên tập trung bằng Resource Groups Thao tác chuyên sâu bằng Console \u0026amp; CLI Trải nghiệm thực tế với Infrastructure as Code thông qua CloudFormation để tạo môi trường nhất quán.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Nhật ký công việc Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Học cách quản lý quyền truy cập EC2 bằng IAM, sử dụng tag tài nguyên và permission boundaries. Thiết lập và cấu hình công cụ giám sát như Grafana và AWS CloudWatch. Triển khai AWS Systems Manager để quản lý bản vá và thực thi lệnh từ xa. Tối ưu hóa EC2 bằng thực hành right-sizing và AWS Compute Optimizer. Áp dụng mã hóa cho dữ liệu S3 bằng AWS KMS và cấu hình ghi nhật ký kiểm toán. Phân tích chi phí và mô hình sử dụng AWS bằng Cost Explorer. Xây dựng pipeline và data lake sử dụng S3, Kinesis, Glue, Athena và QuickSight. Tự động hóa provisioning hạ tầng bằng template AWS CloudFormation. Công việc thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Quản lý truy cập dịch vụ EC2 bằng tag tài nguyên thông qua IAM: + Tạo một IAM user để chuẩn bị + Tạo một custom IAM Policy để xác định quyền cụ thể + Thiết lập một IAM Role để user hoặc dịch vụ có thể assume + Kiểm tra policy bằng cách đổi role và thử truy cập - Bắt đầu với Grafana cơ bản: + Tạo VPC và subnet để thiết lập môi trường mạng + Cấu hình Security Group để kiểm soát lưu lượng vào/ra + Khởi chạy một EC2 instance để host ứng dụng giám sát + Tạo IAM User và Role để truy cập an toàn tài nguyên AWS + Gán IAM Role cho EC2 instance + Cài đặt Grafana trên EC2 instance + Thiết lập dashboard giám sát trong Grafana 10/13/2025 10/13/2025 IAM services: https://000028.awsstudygroup.com/ Grafana basic: https://000029.awsstudygroup.com/ 3 - Giới hạn quyền người dùng với IAM Permission Boundary: + Thực hiện các bước chuẩn bị cho bài tập + Tạo một policy hạn chế để định nghĩa quyền lớn nhất được cho phép + Tạo một IAM user mới với quyền bị giới hạn + Kiểm tra giới hạn của IAM user để xác minh permission boundary - Quản lý bản vá và chạy lệnh trên nhiều server bằng AWS Systems Manager: + Tạo VPC và Subnet cho môi trường mạng + Khởi chạy một EC2 Windows công khai + Tạo một IAM Role với quyền cần thiết + Gán IAM Role cho EC2 instance + Cấu hình và sử dụng Patch Manager để quản lý vá + Dùng Run Command để thực thi lệnh trên các server 10/14/2025 10/14/2025 IAM permission boundary: https://000030.awsstudygroup.com/ AWS Systems Manager: https://000031.awsstudygroup.com/ 4 - Thực hiện best practice right-sizing cho Amazon EC2: + Làm quen với Amazon CloudWatch để giám sát + Tạo và gán IAM Role cho CloudWatch Agent + Cài đặt CloudWatch Agent trên EC2 instance + Sử dụng AWS Compute Optimizer để phân tích và tối ưu cấu hình EC2 - Mã hóa dữ liệu lưu trữ tại S3 bằng AWS KMS: + Tạo các IAM policy, role, group và user cần thiết + Thiết lập một KMS key + Tạo bucket S3 và upload dữ liệu + Cấu hình AWS CloudTrail để ghi nhật ký và sử dụng Amazon Athena để truy vấn dữ liệu + Kiểm tra và chia sẻ dữ liệu đã được mã hóa trên S3 10/15/2025 10/15/2025 EC2 right-sizing: https://000032.awsstudygroup.com/ S3 encryption with KMS: https://000033.awsstudygroup.com/ 5 - Trực quan hóa và phân tích chi phí bằng AWS Cost Explorer: + Xem dữ liệu chi phí và sử dụng theo dịch vụ và theo tài khoản + Phân tích phạm vi và hiệu quả của Savings Plans và Reserved Instances + Đánh giá tính co giãn chi phí (cost elasticity) + Tạo báo cáo tùy chỉnh cho các instance EC2 + Dùng Cost Explorer để phân tích chi tiết chi phí + Kiểm tra chi phí truyền dữ liệu cho các kiến trúc phổ biến - Xây dựng data lake trên AWS: + Tạo IAM Role và Policy với quyền cần thiết + Thiết lập bucket S3 để lưu trữ dữ liệu + Tạo Kinesis Data Firehose delivery stream để thu thập dữ liệu + Dùng Glue Crawler để tạo data catalog + Thực hiện chuyển đổi dữ liệu + Phân tích dữ liệu bằng Amazon Athena + Trực quan hóa dữ liệu bằng Amazon QuickSight 10/16/2025 10/17/2025 AWS Cost Explorer: https://000034.awsstudygroup.com/ Data lake on AWS: https://000035.awsstudygroup.com/ 6 - Nghiên cứu AWS CloudWatch cho giám sát và observability: + Khám phá CloudWatch Metrics: xem, tìm kiếm và sử dụng expressions + Làm việc với CloudWatch Logs, Logs Insights và Metric Filters + Cấu hình CloudWatch Alarms để gửi thông báo + Tạo CloudWatch Dashboards để trực quan hóa dữ liệu - Tự động hóa hạ tầng bằng AWS CloudFormation: + Tạo IAM Users và Roles để chuẩn bị + Phát triển template CloudFormation cơ bản để provision tài nguyên + Khám phá các tính năng nâng cao như Custom Resources với Lambda + Sử dụng Mappings, StackSets và Drift Detection cho các triển khai phức tạp 10/17/2025 10/17/2025 AWS CloudWatch: https://000036.awsstudygroup.com/ AWS CloudFormation: https://000037.awsstudygroup.com/ Thành tựu tuần 6: Quản lý truy cập EC2 qua IAM: Cấu hình chính sách truy cập dựa trên tag tài nguyên Áp dụng permission boundaries để giới hạn khả năng của người dùng Thiết lập hệ thống giám sát và observability: Triển khai Grafana trên EC2 để tạo dashboard tùy chỉnh Cấu hình CloudWatch Metrics, Logs và Alarms để giám sát tài nguyên Triển khai khả năng của AWS Systems Manager: Sử dụng Patch Manager để tự động cập nhật bản vá cho server Thực thi lệnh từ xa trên nhiều instance bằng Run Command Ứng dụng tối ưu hóa EC2 và quản lý chi phí: Cài và cấu hình CloudWatch Agent để thu thập metric chi tiết Phân tích cấu hình instance bằng AWS Compute Optimizer Xem xét mẫu chi phí và xu hướng bằng Cost Explorer Bảo mật lưu trữ dữ liệu bằng mã hóa: Tạo và quản lý KMS key cho mã hóa S3 Thiết lập CloudTrail và dùng Athena cho phân tích nhật ký kiểm toán Xây dựng pipeline và data lake: Cấu hình Kinesis Data Firehose để ingest dữ liệu streaming Tạo data catalog bằng Glue Crawler Phân tích dữ liệu bằng Athena và trực quan hóa bằng QuickSight Tự động hóa triển khai hạ tầng bằng CloudFormation: Phát triển template để provisioning tài nguyên Khám phá các tính năng nâng cao như Lambda-backed custom resources và StackSets "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Nhật ký công việc Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Nâng cao kỹ năng thực hành với Amazon DynamoDB, bao gồm thao tác cơ bản, mô hình dữ liệu nâng cao và kiến trúc đa vùng/toàn cầu. Thiết lập liên kết danh tính (identity federation) và cấu hình IAM roles, đồng thời áp dụng các kỹ thuật tối ưu chi phí giữa AWS và Azure AD. Triển khai và vận hành ứng dụng sử dụng Lightsail, containers, Step Functions và IAM roles để đảm bảo truy cập an toàn. Sử dụng Cloud9, Elastic Beanstalk và công cụ CI/CD để tự động hóa pipeline phân phối ứng dụng. Cải thiện posture bảo mật AWS qua các best practice IAM cơ bản, kiểm soát phát hiện (detective controls), ứng phó sự cố và bảo vệ hạ tầng. Thiết kế và tự động hóa kiến trúc microservices sử dụng Lambda, DynamoDB, Step Functions và CodeStar. Công việc đã thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Kiến thức cơ bản về DynamoDB: + Tạo bảng và nạp dữ liệu mẫu + Dùng AWS CLI để đọc/query/scan/insert/update dữ liệu + Kiểm tra dữ liệu bảng và GSI trên Console + Thực hiện backup và restore (PITR và on-demand) - Mẫu thiết kế nâng cao cho DynamoDB: + Xem xét đơn vị dung lượng (RCU/WCU) và hành vi phân vùng + So sánh scan tuần tự và scan song song về hiệu suất + Áp dụng write-sharding cho GSI, key overloading và sparse GSI + Sử dụng composite key và adjacency list cho các truy vấn phức tạp - Capture thay đổi dữ liệu (CDC): + Bật DynamoDB Streams và xử lý các thay đổi + Tạo Lambda để tiêu thụ sự kiện stream + Khám phá CDC với Kinesis Data Streams như phương án thay thế - Ứng dụng serverless toàn cầu với DynamoDB: + Provision các thành phần backend serverless + Cấu hình Global Tables để replicate đa vùng + Tương tác với giao diện mẫu của ứng dụng toàn cầu - Mô hình dữ liệu cho game player: + Thiết kế mô hình dữ liệu dựa trên thực thể và pattern truy cập + Xác định khóa chính và bố cục bảng + Dùng sparse GSI để tìm các game còn trống + Thêm inverted index để lấy lịch sử game của người dùng - Phân tích chi phí \u0026amp; hiệu năng bằng Glue và Athena: + Dựng database bằng Glue Crawlers + Dùng Athena để truy vấn báo cáo chi phí và sử dụng + Áp dụng chiến lược tagging để phân bổ chi phí 10/20/2025 10/20/2025 CDK basic: https://000038.awsstudygroup.com/ Amazon DynamoDB Immersion: https://000039.awsstudygroup.com/ Analysis with Glue and Athena: https://000040.awsstudygroup.com/ 3 - Federation IAM từ Azure AD: + Chuẩn bị Azure AD (tenant, users) + Tạo Enterprise Application trên Azure để kết nối với AWS + Cấu hình Identity Provider và các IAM role tương ứng trên AWS + Đồng bộ roles và cấp quyền truy cập console AWS cho user federated + Kiểm tra đăng nhập từ Azure AD vào AWS Console - Tối ưu chi phí (Savings Plans \u0026amp; RIs): + So sánh Savings Plans và Reserved Instances + Dùng khuyến nghị của AWS để tìm cơ hội tiết kiệm + Mua Savings Plan để giảm chi phí EC2 + Xem xét các loại RI và tùy chọn Reserved DB Instances cho RDS - Chuyển đổi schema \u0026amp; di cư CSDL: + Chuẩn bị EC2 host và cài Schema Conversion Tool (SCT) + Cấu hình DB nguồn (Oracle/SQL Server) và chuyển đổi schema sang định dạng đích + Tạo DMS replication instance, endpoints và task di cư + Thực thi di cư và replicate các thay đổi liên tục + Thử nghiệm DMS Serverless để auto-scaling trong quá trình di cư + Giám sát tiến trình di cư bằng CloudWatch và logs của task - IAM roles \u0026amp; condition policies: + Tạo IAM groups và users + Thiết lập admin role và bật tính năng switch role + Hạn chế sử dụng role theo địa chỉ IP và điều kiện theo thời gian - Triển khai \u0026amp; quản lý ứng dụng trên Lightsail: + Khởi chạy database và WordPress trên Lightsail + Cấu hình mạng và thiết lập ứng dụng + Triển khai Prestashop và Akaunting + Bảo mật ứng dụng, tạo snapshot để backup, nâng cấp kích thước instance và cấu hình alarm 10/21/2025 10/21/2025 IAM Federation with Azure AD: https://000041.awsstudygroup.com/ AWS Cost Optimization: https://000042.awsstudygroup.com/ Database Migration with DMS: https://000043.awsstudygroup.com/ IAM Roles and Conditions: https://000044.awsstudygroup.com/ Amazon Lightsail Applications: https://000045.awsstudygroup.com/ 4 - Lightsail containers: + Tạo dịch vụ container trên Lightsail và deploy image công cộng + Cấp phát một Lightsail instance, cài Docker và AWS CLI + Build, push và deploy image container tùy chỉnh từ instance - AWS Step Functions: + Khởi tạo môi trường Cloud9 và triển khai dịch vụ mẫu + Tạo workflow Step Functions để điều phối Lambda bằng Task states + Thêm nhánh với Choice states, quản lý input/output trạng thái, và dùng Wait tokens + Triển khai xử lý lỗi (retry/catch) và thực thi công việc song song (Parallel) - Cấp quyền ứng dụng bằng IAM roles: + Tạo EC2 instance và bucket S3 cho môi trường thử nghiệm + Minh họa hạn chế khi dùng access key tồn tại lâu dài + Tạo IAM role cho EC2 với quyền truy cập S3 và gắn role vào instance 10/22/2025 10/22/2025 Lightsail Containers: https://000046.awsstudygroup.com/ AWS Step Functions: https://000047.awsstudygroup.com/ IAM Roles for Applications: https://000048.awsstudygroup.com/ 5 - Cloud9 cơ bản: + Tạo môi trường Cloud9 + Sử dụng command line, chỉnh sửa file và chạy AWS CLI trong Cloud9 - Triển khai ứng dụng monolithic lên Elastic Beanstalk: + Thiết lập key pair, CloudFormation stack và database + Cấu hình và truy cập instance, thử nghiệm local bằng Eclipse và deploy lên Beanstalk + Cập nhật ứng dụng và kiểm tra endpoint API - Pipeline release tự động: + Tạo CodeStar project và kết nối Eclipse với CodeCommit + Thay ứng dụng mẫu, kích hoạt pipeline và deploy Windows Service bằng CodeDeploy tới EC2 + Giám sát deployment từ IDE và công cụ pipeline - Thực hành bảo mật AWS cơ bản: + Bảo vệ tài khoản root và bật MFA + Tạo IAM admin user/group để tránh dùng root hàng ngày + Áp dụng chính sách mật khẩu mạnh và cân nhắc SCP để làm guardrails cho Organization - Phân tích \u0026amp; xác thực IAM: + Dùng IAM Access Analyzer để kiểm tra least-privilege + Tạo và test cross-account role cho truy cập tạm thời + Kiểm tra resource policies để phát hiện lộ thông tin public hoặc cross-account + Xem báo cáo last-accessed để loại bỏ quyền không dùng đến 10/23/2025 10/23/2025 AWS Cloud9: https://000049.awsstudygroup.com/ Elastic Beanstalk: https://000050.awsstudygroup.com/ CI/CD Pipeline: https://000051.awsstudygroup.com/ AWS Well-Architected Security Workshop: https://catalog.workshops.aws/well-architected-security 6 - Tạo microservice: + Cấu hình Eclipse IDE và phát triển Lambda function + Test cục bộ và deploy lên AWS Lambda + Triển khai ImageManager Lambda và tự động hóa bằng CodeStar CI/CD - Refactor dữ liệu \u0026amp; workflow: + Provision CloudFormation stack và tạo bảng DynamoDB mới với GSI + Xây Scan \u0026amp; Query microservice, tạo API, cập nhật IAM policy và redeploy qua CodeStar + Triển khai Calculator microservice dùng Step Functions + Lambda - Detective controls \u0026amp; incident response: + Triển khai GuardDuty và phân tích findings + Tập hợp, ưu tiên findings trong Security Hub và cấu hình remediation tự động + Dùng Detective để phân tích nguyên nhân gốc rễ của sự cố bảo mật - Bảo vệ hạ tầng: + Thiết kế VPC với phân đoạn subnet và security groups phù hợp + Triển khai Network Firewall để kiểm tra lưu lượng giữa các subnet và ra/vào Internet + Cấu hình WAF để bảo vệ ứng dụng web khỏi tấn công phổ biến + Xem xét AWS Shield Advanced cho chiến lược giảm thiểu DDoS - Bảo vệ dữ liệu \u0026amp; mã hóa: + Dùng Amazon Macie để phát hiện và phân loại dữ liệu nhạy cảm trong S3 + Áp dụng KMS key do khách hàng quản lý để mã hóa S3/EBS + Cấp SSL/TLS qua ACM cho load balancer + Quản lý và xoay vòng bí mật bằng Secrets Manager 10/24/2025 10/24/2025 Create Microservice: https://000052.awsstudygroup.com/ Refactor Data and Workflows: https://000053.awsstudygroup.com/ AWS Well-Architected Security Workshop: https://catalog.workshops.aws/well-architected-security Thành tựu tuần 7: Có kinh nghiệm thực tế vững với Amazon DynamoDB: đã tạo bảng, nạp dữ liệu, sử dụng GSI và composite keys, bật backup, và triển khai change-data-capture qua Streams và Kinesis.\nThực hiện phân tích chi phí và hiệu năng bằng cách kết hợp DynamoDB metrics với AWS Glue và Amazon Athena; thử nghiệm tagging để cải thiện phân bổ chi phí.\nTriển khai federation danh tính và quản trị IAM:\nCấu hình federation Azure AD → AWS, đồng bộ IAM roles và kiểm chứng truy cập console federated. Tạo IAM groups, users và roles với chính sách có điều kiện (theo IP và theo thời gian). Nâng cao kỹ năng tối ưu chi phí và di cư cơ sở dữ liệu bằng cách đánh giá Savings Plans và Reserved Instances; thực hành chuyển đổi schema và di cư dữ liệu với AWS SCT và DMS (bao gồm DMS Serverless và giám sát).\nTriển khai và quản lý ứng dụng trên Lightsail và dịch vụ container: chạy WordPress/Prestashop/Akaunting, quản lý snapshot và alarm, và build image Docker tùy chỉnh để deploy.\nXây dựng orchestration và bảo mật truy cập ứng dụng:\nPhát triển workflow Step Functions (Task, Choice, Wait, Retry/Catch, Parallel). Ưu tiên dùng IAM roles thay vì access keys lâu dài; gắn role cho EC2 để truy cập S3 an toàn. Tự động hóa vòng đời ứng dụng và CI/CD:\nSử dụng Cloud9, CodeStar, CodeCommit, CodeDeploy và Elastic Beanstalk để tối ưu quy trình phát triển và triển khai tự động. Củng cố posture bảo mật tổ chức:\nCứng hóa tài khoản root (MFA), xác định user/group admin, áp dụng chính sách mật khẩu, cân nhắc SCP, và dùng IAM Access Analyzer cùng báo cáo last-accessed để thu hẹp quyền. Xây dựng microservices và lớp bảo mật:\nTriển khai microservices dựa trên Lambda + DynamoDB + Step Functions, tự động hóa triển khai bằng CodeStar, và triển khai các công cụ giám sát/bảo mật (GuardDuty, Security Hub, Detective) cùng các biện pháp bảo vệ mạng/dữ liệu (VPC design, Network Firewall, WAF, Shield Advanced, Macie, KMS, ACM, Secrets Manager). "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8 Áp dụng Infrastructure as Code với AWS CloudFormation để triển khai, cập nhật và mở rộng môi trường ứng dụng. Tăng cường độ tin cậy của hệ thống thông qua kiểm thử khả năng chịu lỗi, Auto Scaling và cơ chế tự phục hồi. Xây dựng và bảo mật kiến trúc hiện đại như serverless SPA với xác thực và theo dõi hiệu năng. Khám phá các dịch vụ AI, lưu trữ và phân phối nội dung: Amazon Polly, Rekognition, Lex, S3 và CloudFront. Giám sát tài nguyên bằng CloudWatch Dashboard trên nhiều hệ điều hành và chuẩn bị cho bài đánh giá cuối tuần. Công việc đã hoàn thành trong tuần Ngày Công Việc Ngày Bắt Đầu Ngày Hoàn Thành Tài Liệu Tham Khảo 2 - Infrastructure as Code với CloudFormation + Triển khai VPC và các thành phần mạng cơ bản bằng CloudFormation + Khởi chạy ứng dụng web đa tầng trên VPC + Xem lại kiến trúc đang chạy (load balancer, Auto Scaling group, EC2) + Kiểm tra tài nguyên và outputs của stack để hiểu quá trình triển khai - Health Check nâng cao \u0026amp; Xử lý sự cố phụ thuộc + Triển khai web stack cơ bản bằng CloudFormation + Mô phỏng lỗi phụ thuộc và quan sát hành vi của ứng dụng + Cấu hình deep health check cho ALB + Triển khai cơ chế “fail open” để duy trì chức năng tối thiểu khi có lỗi dịch vụ - Nâng cấp hạ tầng bằng CloudFormation + Triển khai stack ban đầu và phân tích các thành phần + Cập nhật stack bằng cách thay đổi tham số + Mở rộng template bằng cách thêm S3 bucket + Thêm EC2 mới với cấu hình tùy chỉnh + Triển khai cùng một stack ở Region khác - Tách Monolith thành Microservices + Chuẩn bị môi trường và kết nối vào Windows instance + Phân tích kiến trúc ứng dụng monolithic + Xây dựng và triển khai microservices: Advert, Invoice, ShoppingCart, Order, User + Cung cấp nội dung tĩnh qua microservice Static + Kiểm thử tổng thể hệ thống microservices 10/27/2025 10/27/2025 AWS Well-Architected Reliability Workshop https://catalog.workshops.aws/well-architected-reliability Refactoring to Microservices https://000054.awsstudygroup.com/ 3 - Kiểm thử tính chịu lỗi với AWS FIS + Tạo IAM roles và policies cho FIS + Xây dựng template thí nghiệm nhắm vào tài nguyên cụ thể + Chạy thí nghiệm gây lỗi và theo dõi tác động + Xem log và kết quả để đánh giá hành vi hệ thống - Cấu hình Auto Scaling cho tải \u0026amp; khôi phục + Tạo launch template cho EC2 web-tier + Cấu hình target group cho ALB + Tạo Auto Scaling group + Triển khai load generator và xác nhận hành vi scale-out/scale-in - Thay thế tự động qua Health Checks + Tắt 1 EC2 thủ công để kích hoạt cơ chế tự phục hồi + Xác minh ASG tạo instance mới và health check của ALB - Thiết lập môi trường + Tạo Key Pair + Triển khai hạ tầng nền tảng qua CloudFormation + Kết nối vào Windows instance để cấu hình môi trường - Triển khai Serverless SPA + Tạo table DynamoDB + Xây dựng và triển khai Lambda microservice + Cấu hình API qua API Gateway + Tạo CI/CD pipeline với CodeStar + Triển khai SPA và xây client gọi API - Xác thực \u0026amp; Phân quyền + Tích hợp Cognito User Pools + Bảo vệ API/Lambda bằng xác thực + Tạo luồng đăng ký, đăng nhập người dùng + Kiểm thử toàn bộ auth flow - Theo dõi hiệu năng bằng X-Ray + Tích hợp AWS X-Ray để theo dõi request và tìm bottleneck 10/28/2025 10/28/2025 AWS Well-Architected Reliability Workshop https://catalog.workshops.aws/well-architected-reliability Serverless Web Application https://000055.awsstudygroup.com/ 4 - Tích hợp Amazon Polly + Trải nghiệm Polly trên console + Tạo giọng nói và speech marks bằng CLI + Sử dụng Java SDK để tổng hợp giọng nói - Nhận diện đối tượng \u0026amp; khuôn mặt với Rekognition + Chuẩn bị môi trường + Nhận diện object trong hình ảnh + Triển khai nhận diện khuôn mặt cơ bản qua ứng dụng mẫu - Xây chatbot với Amazon Lex + Triển khai ứng dụng và APIs nền tảng + Tạo và tinh chỉnh Lex bot + Implement Lambda fulfillment + Publish bot - Triển khai Website Tĩnh qua S3 \u0026amp; CloudFront + Tạo S3 bucket và upload nội dung web + Bật static website hosting + Cấu hình quyền truy cập + Tạo CloudFront distribution - Bảo vệ dữ liệu \u0026amp; replication trong S3 + Bật versioning + Thực hành di chuyển object trong bucket + Cấu hình cross-region replication 10/29/2025 10/29/2025 AI Services Integration https://000056.awsstudygroup.com/ S3 \u0026amp; CloudFront https://000057.awsstudygroup.com/ 5 - CloudWatch Dashboards để giám sát + Tạo dashboards để trực quan hóa metrics + Thêm metric widgets và Logs Insights - Giám sát EC2 Windows + Triển khai VPC networking + Khởi chạy \u0026amp; cấu hình EC2 Windows + Xây dashboard tùy chỉnh + Thêm CPU, network và performance metrics + Tạo tải thử để quan sát thay đổi - Giám sát EC2 Linux + Triển khai VPC và khởi chạy EC2 Linux với web server + Tạo dashboard giám sát + Theo dõi CPU và network performance + Tạo tải thử để kiểm tra đáp ứng hệ thống 10/30/2025 10/30/2025 AWS Well-Architected Performance Efficiency Workshop https://catalog.workshops.aws/well-architected-performance-efficiency/ 6 - NGÀY THI 10/31/2025 10/31/2025 Thành tựu đạt được trong tuần 8 Thành thạo CloudFormation: triển khai VPC, web stack đa tầng, cập nhật hạ tầng và triển khai multi-region. Nâng cao hiểu biết về tính chịu lỗi: fault injection, deep health checks, Auto Scaling, self-healing. Tách ứng dụng monolithic thành microservices (Advert, Invoice, ShoppingCart, Order, User, Static) và kiểm thử thành công toàn bộ hệ thống. Xây dựng serverless SPA hoàn chỉnh với API Gateway, Lambda, DynamoDB, CodeStar CI/CD, Cognito và X-Ray. Có kinh nghiệm thực tế với Polly, Rekognition, Lex, S3 và CloudFront. Tăng kỹ năng giám sát qua CloudWatch Dashboards với cả EC2 Windows và Linux. Hoàn thành bài kiểm tra và tổng hợp kiến thức về reliability, serverless, AI services và monitoring. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]